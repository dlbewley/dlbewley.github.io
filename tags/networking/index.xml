<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Networking on GUI Free Life</title><link>http://guifreelife.com/tags/networking/</link><description>Recent content in Networking on GUI Free Life</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 02 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://guifreelife.com/tags/networking/index.xml" rel="self" type="application/rss+xml"/><item><title>OpenShift Virtual Guest Tagging</title><link>http://guifreelife.com/blog/2025/01/02/OpenShift-Virtualization-VLAN-Guest-Tagging/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2025/01/02/OpenShift-Virtualization-VLAN-Guest-Tagging/</guid><description>&lt;p>Some workloads require the use of VLAN interfaces in virtual machines. VMware terms this feature &amp;ldquo;Virtual Guest Tagging&amp;rdquo; or &amp;ldquo;VLAN Guest Tagging&amp;rdquo; while OpenStack calls it &amp;ldquo;VLAN-aware instances&amp;rdquo;. See how OpenShift Virtualization can pass 802.1q trunks to VMs using a traditional Linux Bridge interface.&lt;/p></description></item><item><title>Open Virtual Networking Inspection with OpenShift</title><link>http://guifreelife.com/blog/2024/11/19/Open-Virtual-Network-Inspection-on-OpenShift/</link><pubDate>Tue, 19 Nov 2024 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2024/11/19/Open-Virtual-Network-Inspection-on-OpenShift/</guid><description>&lt;p>Accessing the details of the software defined networking features of OpenShift can be helpful for deeper troubleshooting or enhanced understanding. You&amp;rsquo;ll not find a full explanation of &lt;a href="https://www.ovn.org/en/" title="OpenVirtualNetwork">Open Virtual Network&lt;/a> or &lt;a href="https://ovn-kubernetes.io/" title="OVN-Kubernetes">OVN-Kubernetes&lt;/a> here, but you will learn how to quickly peer inside and investigate their inner workings.&lt;/p></description></item><item><title>OpenShift 4 on OpenStack Networking and Installation</title><link>http://guifreelife.com/blog/2020/02/15/OpenShift-4-on-OpenStack-Networking-and-Installation/</link><pubDate>Sat, 15 Feb 2020 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2020/02/15/OpenShift-4-on-OpenStack-Networking-and-Installation/</guid><description>&lt;p>OpenShift Containter Platform 4 is much more like Tectonic than OpenShift 3. Particularly when it comes to &lt;a href="https://docs.openshift.com/container-platform/4.3/architecture/architecture-installation.html">installation&lt;/a> and node management. Rather then building machines and running &lt;a href="https://github.com/openshift/openshift-ansible/tree/release-3.11">an Ansible playbook&lt;/a> to configure them you now have the option of setting a fewer paramters in an install config running an installer to build and configure the cluster from scratch.&lt;/p>
&lt;p>I would like to illustrate how the basics of the networking might look when &lt;a href="https://docs.openshift.com/container-platform/4.3/installing/installing_openstack/installing-openstack-installer-custom.html">installing OpenShift on OpenStack&lt;/a>. I also wanted an excuse to try out a new iPad sketch app. These notes are based on recent 4.4 nightly builds on OSP 13 Queens.&lt;/p></description></item><item><title>Creating OpenStack Provider Network for Use by a Single Project</title><link>http://guifreelife.com/blog/2018/10/30/OpenStack-Private-Provider-Network/</link><pubDate>Tue, 30 Oct 2018 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2018/10/30/OpenStack-Private-Provider-Network/</guid><description>&lt;p>OpenStack supports &lt;a href="https://docs.openstack.org/install-guide/launch-instance-networks-provider.html">&amp;ldquo;provider&amp;rdquo; networks&lt;/a>, which are networks that pre-exist in your physical infrastructure and are &amp;ldquo;provided&amp;rdquo; to the cloud users rather than created by the user. Only an admin is permitted to create a provider network.&lt;/p>
&lt;p>A prequisite is the provider network must be plumbed to the external bridge on your controller and nova nodes.&lt;/p>
&lt;p>Here is an Ansible playbook to create a project, place a unshared provider network and subnet in that project. Afterwards we will grant access to the members of this project using the openstack client. It &lt;a href="https://docs.ansible.com/ansible/latest/modules/list_of_cloud_modules.html#openstack">does not appear&lt;/a> that Ansible has a OpenStack network RBAC module at this time.&lt;/p></description></item><item><title>Load balancing of OpenShift HA Routers Mind the GARP</title><link>http://guifreelife.com/blog/2018/02/16/OpenShift-Router-LoadBalancing/</link><pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2018/02/16/OpenShift-Router-LoadBalancing/</guid><description>&lt;p>&lt;a href="http://guifreelife.com/blog/2016/03/01/OpenShift-3-HA-Routing">OpenShift HA Routing&lt;/a> uses &lt;a href="https://docs.openshift.com/container-platform/latest/architecture/networking/haproxy-router.html">haproxy application routers&lt;/a> to get traffic into the cluster. These application routers are made redundant by running &lt;a href="https://docs.openshift.com/container-platform/latest/admin_guide/high_availability.html">ipfailover (keepalived)&lt;/a> pods to maintain a set of Virtual IPs on each infrastructure node where the application routers run. These VIPs are then referenced by round robin DNS records to enable a measure of load balancing.&lt;/p>
&lt;p>OK, so now you are load balancing at the network layer, but what about the link layer?
Did you know that even &lt;em>if&lt;/em> you somehow manage to perfectly balance traffic among the VIPs using RR DNS you could still be using only one of your application routers? Well you could be!&lt;/p></description></item><item><title>OpenShift High Availability - Routing</title><link>http://guifreelife.com/blog/2016/03/01/OpenShift-3-HA-Routing/</link><pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/03/01/OpenShift-3-HA-Routing/</guid><description>&lt;p>Highly availabile containers in OpenShift are baked into the cake thanks to &lt;a href="https://docs.openshift.com/enterprise/3.1/architecture/core_concepts/deployments.html#replication-controllers">replication controllers&lt;/a> and &lt;a href="https://docs.openshift.com/enterprise/3.1/architecture/core_concepts/pods_and_services.html#services">service load balancing&lt;/a>, but there are plenty of other single points of failure. Here is how to eliminate many of those.&lt;/p>
&lt;h1 id="single-points-of-failure">Single Points of Failure&lt;/h1>
&lt;p>The &lt;a href="https://docs.openshift.com/dedicated/3.1/architecture/infrastructure_components/kubernetes_infrastructure.html">components&lt;/a> of OpenShift include:&lt;/p>
&lt;ul>
&lt;li>Master controller manager server and API endpoint&lt;/li>
&lt;li>Etcd configuration and state storage&lt;/li>
&lt;li>Docker Registry&lt;/li>
&lt;li>Router haproxy&lt;/li>
&lt;/ul>
&lt;p>This post is mostly about adding high availability to the routing layer.&lt;/p></description></item><item><title>Notes on SNMP MIBs OIDs and Grey Whiskers</title><link>http://guifreelife.com/blog/2015/09/08/SNMP-OIDs/</link><pubDate>Tue, 08 Sep 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/09/08/SNMP-OIDs/</guid><description>&lt;p>With as many grey whiskers as I have, you would think I could grok SNMP in my sleep by now. Unfortunately, everytime I have to deal with it I get frustrated, wonder where the hell my notes from last time are, and start cursing. From now on, here are my notes!&lt;/p>
&lt;p>I&amp;rsquo;m typically using &lt;a href="http://www.zabbix.com/">Zabbix&lt;/a> to poll SNMP OIDs and place the MIBs on the Zabbix server or the Zabbix proxy responsible for SNMP in &lt;code>/usr/share/snmp/mibs&lt;/code>.&lt;/p></description></item></channel></rss>