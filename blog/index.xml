<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blogs on GUI Free Life</title><link>http://guifreelife.com/blog/</link><description>Recent content in Blogs on GUI Free Life</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 11 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://guifreelife.com/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Using Placements to Apply Open Cluster Management Policies to Kubernetes Clusters</title><link>http://guifreelife.com/blog/2024/03/11/Placing-Open-Cluster-Management-Policies-on-Kubernetes/</link><pubDate>Mon, 11 Mar 2024 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2024/03/11/Placing-Open-Cluster-Management-Policies-on-Kubernetes/</guid><description>&lt;p>&lt;a href="https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/" title="RHACM">Red Hat Advanced Cluster Management&lt;/a> (RHACM) enables Open Cluster Management policy driven governance of an entire fleet of Kubernetes clusters. Associating policies with the appropriate clusters is a very flexible operation and requires understanding resources like Placements and ManagedClusterSetBindings. So let&amp;rsquo;s get familiar!&lt;/p></description></item><item><title>Storing OpenShift Credentials with 1Password</title><link>http://guifreelife.com/blog/2023/09/22/Storing-OpenShift-Credentials-with-1Password/</link><pubDate>Fri, 22 Sep 2023 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2023/09/22/Storing-OpenShift-Credentials-with-1Password/</guid><description>&lt;p>If you find yourself frequently rebuilding OpenShift clusters and potentially reusing cluster names, you may find it challanging to manage the credentials consistently and securely. Here is a solution using &lt;a href="https://developer.1password.com/docs/cli/get-started/" title="Get started with 1Password CLI">1Password&lt;/a>.&lt;/p></description></item><item><title>Accessing the Ceph CLI with OpenShift Data Foundation</title><link>http://guifreelife.com/blog/2023/04/06/Accessing-Ceph-CLI-with-OpenShift-Data-Foundation/</link><pubDate>Thu, 06 Apr 2023 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2023/04/06/Accessing-Ceph-CLI-with-OpenShift-Data-Foundation/</guid><description>&lt;p>The Ceph Toolbox is not recommended or supported for use with OpenShift Data Foundation, but sometimes you want a client to troubleshoot with anyway.&lt;/p></description></item><item><title>Extracting TLS CA Certificates from Kubeconfig File</title><link>http://guifreelife.com/blog/2023/03/09/Extracting-CA-Certs-From-Kubeconfig/</link><pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2023/03/09/Extracting-CA-Certs-From-Kubeconfig/</guid><description>&lt;p>OpenShift creates a number of Certificate Authorities to sign TLS certificates which secure functions including load balancing of the API and Ingress services.
Recent versions of openshift-install will place all the CA certificates in the generated &lt;code>auth/kubeconfig&lt;/code> file.&lt;/p>
&lt;p>Here is how to extract and split those certificates into individual files which eases the process of trusting them particularly on a Mac.&lt;/p></description></item><item><title>Autoscaling OpenShift Workloads With Custom Prometheus Metrics</title><link>http://guifreelife.com/blog/2022/11/03/Autoscaling-OpenShift-Workloads-with-Custom-Prometheus-Metrics/</link><pubDate>Thu, 03 Nov 2022 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2022/11/03/Autoscaling-OpenShift-Workloads-with-Custom-Prometheus-Metrics/</guid><description>&lt;p>Kubernetes enables the automated scaling of applications to meet workload demands. Historically only memory and CPU consumption could be considered in scaling decisions, but the OpenShift Custom Metrics Autoscaler operator and KEDA remove that limitation. Read on to learn how OpenShift enables auto scaling based on the metrics that are important to your business.&lt;/p></description></item><item><title>Hybrid Cloud Management With Red Hat</title><link>http://guifreelife.com/blog/2022/09/19/Hybrid-Cloud-Management-with-Red-Hat/</link><pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2022/09/19/Hybrid-Cloud-Management-with-Red-Hat/</guid><description>&lt;p>Whether workloads are in the datacenter, in the cloud, or even in multiple clouds, OpenShift provides a consistent experience. And the Hybrid Cloud Console is your entry point for Red Hat cloud services to enable the most effective use of each environment. This video demo walks through the provisioning of &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/aws" title="Red Hat OpenShift Service on AWS">ROSA&lt;/a> and using Red Hat Advanced Cluster Management with EKS. Finally, &lt;a href="https://www.redhat.com/en/technologies/management/advanced-cluster-management" title="Red Hat Advanced Cluster Management for Kubernetes">RHACM&lt;/a> policies are deployed to ensure automatic application of Red Hat Advanced Cluster Security.&lt;/p></description></item><item><title>OpenShift Virtualization on vSphere</title><link>http://guifreelife.com/blog/2022/05/13/OpenShift-Virtualization-on-vSphere/</link><pubDate>Fri, 13 May 2022 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2022/05/13/OpenShift-Virtualization-on-vSphere/</guid><description>&lt;p>OpenShift Virtualization builds upon &lt;a href="https://kubevirt.io" title="KubeVirt.io">KubeVirt&lt;/a> to provide a container native home for your virtual machine workloads. While bare metal is the only officially support platform today, this post will walk through enabling OpenShift Virtualization on vSphere in a lab environment. With nested virtualization you&amp;rsquo;ll be able to spin up containerized VMs bridged to your physical networks.&lt;/p></description></item><item><title>Debugging AWS STS Authentication for OpenShift Operators</title><link>http://guifreelife.com/blog/2022/03/10/Debugging-AWS-STS-Authentication-for-OpenShift-Operators/</link><pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2022/03/10/Debugging-AWS-STS-Authentication-for-OpenShift-Operators/</guid><description>&lt;p>OpenShift supports granular AWS permissions for pods running cluster operators or even user applications. This enhances security by providing only the necessary privileges and nothing more. This post explores debugging authN and authZ of pods attempting to use fine grained IAM roles in combination with AWS secure token service.&lt;/p></description></item><item><title>Red Hat Advanced Cluster Security Walkthrough</title><link>http://guifreelife.com/blog/2021/12/22/Red-Hat-Advanced-Cluster-Security-Walkthrough/</link><pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2021/12/22/Red-Hat-Advanced-Cluster-Security-Walkthrough/</guid><description>&lt;p>Red Hat Advanced Cluster Security for Kubernetes enables organizations to securely build, deploy, and run cloud-native applications anywhere. This video demonstration walks through the major features of RHACS to demonstrate vulnerability management, network segmentation, custom security policies, and more!&lt;/p></description></item><item><title>Red Hat Advanced Cluster Management Walkthrough</title><link>http://guifreelife.com/blog/2021/12/21/Red-Hat-Advanced-Cluster-Management-Walkthrough/</link><pubDate>Tue, 21 Dec 2021 09:00:00 -0800</pubDate><guid>http://guifreelife.com/blog/2021/12/21/Red-Hat-Advanced-Cluster-Management-Walkthrough/</guid><description>&lt;p>Red Hat Advanced Cluster Management for Kubernetes, &lt;a href="https://www.redhat.com/en/technologies/management/advanced-cluster-management" title="Red Hat Advanced Cluster Management for Kubernetes">RHACM&lt;/a>, built on the Open Cluster Management &lt;a href="https://open-cluster-management.io/" title="Open Cluster Management">project&lt;/a>, manages Kubernetes distributions like AKS, EKS, GKE, and OpenShift including the workloads they host. Read on for a demonstration of RHACM features like Cluster Hibernation, Cluster Pools, Multi-cluster application deployment and Observability.&lt;/p>
&lt;p>Skip to the end for the complete &lt;a href="https://www.youtube.com/watch?v=rS9IatJBRP8" title="YouTube Red Hat Advanced Cluster Management Demos">video demo&lt;/a> or take your time and stroll through a few quick GUI Free reanimations on your way there.&lt;/p></description></item><item><title>Protect Gitignored but Tracked Files</title><link>http://guifreelife.com/blog/2021/08/18/Protect-Gitignored-but-Tracked-Files/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2021/08/18/Protect-Gitignored-but-Tracked-Files/</guid><description>&lt;p>Sometimes you want to put files in git that you really shouldn&amp;rsquo;t be putting in git.&lt;/p></description></item><item><title>Recovering kubeconfig for a Cluster Created with RHACM</title><link>http://guifreelife.com/blog/2021/08/13/RHACM-Recover-Created-Cluster-Credentials-and-Kubeconfig/</link><pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2021/08/13/RHACM-Recover-Created-Cluster-Credentials-and-Kubeconfig/</guid><description>Red Hat Advanced Cluster Management for Kubernetes and it&amp;rsquo;s upstream Open Cluster Management automate cluster lifecycle management from creation, configuration, upgrade, and destruction.
If a cluster is created by RHACM you may need to download the kubeadmin password and the kubeconfig. This is easily accomplished by browsing to the RHACM cluster overview, but how do you do the same from the CLI?
ClusterDeployment The creation of a cluster starts with a ClusterDeployment which will be interpreted by Hive.</description></item><item><title>Deploying a Cross-platform Windows and Linux Application to OpenShift</title><link>http://guifreelife.com/blog/2021/07/10/OpenShift-Windows-Containers-part-3/</link><pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2021/07/10/OpenShift-Windows-Containers-part-3/</guid><description>&lt;p>An application can sometimes require diverse components that span technology stacks. There may be a depency on a legacy component built for Windows which may not be suitable for deployment to Linux. The good news is it may still be suitable for deployment to Kubernetes. With a Windows node in your OpenShift cluster you can deploy cross-platform applications that can simultaneously leverage the strengths of Linux and Windows.&lt;/p></description></item><item><title>Adding a Windows Node to an OpenShift Cluster</title><link>http://guifreelife.com/blog/2021/06/03/OpenShift-Windows-Containers-part-2/</link><pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2021/06/03/OpenShift-Windows-Containers-part-2/</guid><description>&lt;p>The Windows Machine Config Operator builds and configures Windows machines to act as nodes in an OpenShift cluster enabling cross platform workloads. This post will demonstrate the addition of a Windows node to an existing cluster and explore the integration of Windows and Kubernetes.&lt;/p></description></item><item><title>Installing OpenShift on Azure for Windows Containers</title><link>http://guifreelife.com/blog/2021/05/18/OpenShift-Windows-Containers-part-1/</link><pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2021/05/18/OpenShift-Windows-Containers-part-1/</guid><description>&lt;p>Adding support for Windows nodes in your OpenShift cluster is a day 2 operation that requires preparation at install time.
It is important to accommodate the hybrid networking requirements for Windows Kubernetes nodes.
Azure specific tasks and gotchas are highlighted in this part 1 of 3 while laying the groundwork applicable to deploying OpenShift on any provider in preparation for managing Windows containers.&lt;/p></description></item><item><title>How do OpenShift Over The Air Updates Work?</title><link>http://guifreelife.com/blog/2021/03/09/Understanding-OpenShift-Over-The-Air-Updates/</link><pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2021/03/09/Understanding-OpenShift-Over-The-Air-Updates/</guid><description>OpenShift 4 extends the operator pattern introduced by CoreOS, and enables automated management of the Kubernetes cluster and the underlying resources including machine instances and operating system configuration. Operator driven over the air updates enable automated updates much like you are accustomed to receiving for your smart phone. What follows is a a technical exploration of the OpenShift over the air updates implementation.
Operators All the Way Down What is an &amp;ldquo;Operator&amp;rdquo;?</description></item><item><title>OpenShift 4 on OpenStack Networking and Installation</title><link>http://guifreelife.com/blog/2020/02/15/OpenShift-4-on-OpenStack-Networking-and-Installation/</link><pubDate>Sat, 15 Feb 2020 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2020/02/15/OpenShift-4-on-OpenStack-Networking-and-Installation/</guid><description>OpenShift Containter Platform 4 is much more like Tectonic than OpenShift 3. Particularly when it comes to installation and node management. Rather then building machines and running an Ansible playbook to configure them you now have the option of setting a fewer paramters in an install config running an installer to build and configure the cluster from scratch.
I would like to illustrate how the basics of the networking might look when installing OpenShift on OpenStack.</description></item><item><title>Playbook to replace bootstrap.kubeconfig and node certificates on OpenShift 3.10 3.11</title><link>http://guifreelife.com/blog/2019/05/09/Replace-Bootstrap-Kubeconfig/</link><pubDate>Thu, 09 May 2019 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2019/05/09/Replace-Bootstrap-Kubeconfig/</guid><description>If you are a serial upgrader like me, you may have found that at one point during your 3.10.xx patching (say 3.10.119) you hit this error during the data plane upgrade:
TASK [openshift_node : Approve the node] ************************************************************ task path: /usr/share/ansible/openshift-ansible/roles/openshift_node/tasks/upgrade/restart.yml:49 Using module file /usr/share/ansible/openshift-ansible/roles/lib_openshift/library/oc_csr_approve.py ... FAILED - RETRYING: Approve the node (30 retries left).Result was: { &amp;#34;all_subjects_found&amp;#34;: [], &amp;#34;attempts&amp;#34;: 1, &amp;#34;changed&amp;#34;: false, &amp;#34;client_approve_results&amp;#34;: [], &amp;#34;client_csrs&amp;#34;: {}, &amp;#34;failed&amp;#34;: true, &amp;#34;invocation&amp;#34;: { &amp;#34;module_args&amp;#34;: { &amp;#34;node_list&amp;#34;: [ &amp;#34;ose-test-node-01.</description></item><item><title>Downgrade Etcd 3.3.11 to 3.2.22 for OpenShift Compatibility</title><link>http://guifreelife.com/blog/2019/02/19/Downgrade-Etcd-for-OpenShift-Compatibility/</link><pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2019/02/19/Downgrade-Etcd-for-OpenShift-Compatibility/</guid><description>While I was working on migrating etcd to my master nodes I was bitten by an incompatible etcd v3.3.11 RPM made available via RHEL Server Extras repo. Before I got to my last master the RPM was no longer available, and the scaleup playbook failed. I became aware that 3.3.11 is not compatible and should not have been made available.
Unfortunately all members of my etcd cluster were already upgraded and the fix is to take down the cluster, downgrade etcd, and restore from snapshot.</description></item><item><title>Etcdctl v2 and v3 Aliases for Peer Authenticated Commands</title><link>http://guifreelife.com/blog/2019/02/08/Etcd-Shortcut-With-Peer-Auth/</link><pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2019/02/08/Etcd-Shortcut-With-Peer-Auth/</guid><description>Getting all the arguments to etcdctl right can be a bit of a pain. Here are a couple of aliases which take advantage of the values in the etcd.conf file.
alias etcd2=&amp;#39;. /etc/etcd/etcd.conf &amp;amp;&amp;amp; \ ETCDCTL_API=2 etcdctl \ --cert-file ${ETCD_PEER_CERT_FILE} \ --key-file ${ETCD_PEER_KEY_FILE} \ --ca-file ${ETCD_PEER_TRUSTED_CA_FILE:-$ETCD_PEER_CA_FILE} \ --endpoints &amp;#34;${ETCD_ADVERTISE_CLIENT_URLS}&amp;#34;&amp;#39; alias etcd3=&amp;#39;. /etc/etcd/etcd.conf &amp;amp;&amp;amp; \ ETCDCTL_API=3 etcdctl \ --cert ${ETCD_PEER_CERT_FILE} \ --key ${ETCD_PEER_KEY_FILE} \ --cacert ${ETCD_PEER_TRUSTED_CA_FILE:-$ETCD_PEER_CA_FILE} \ --endpoints &amp;#34;${ETCD_ADVERTISE_CLIENT_URLS}&amp;#34;&amp;#39; If you are using OpenShift, you may also find that you already have some bash functions enabled by the etcd role in /etc/profile.</description></item><item><title>Migration of Etcd to Masters for OpenShift 3.9 to 3.10 Upgrade</title><link>http://guifreelife.com/blog/2019/02/08/Migration-of-Etcd-to-Masters-for-OpenShift-3.9-Upgrade-to-3.10/</link><pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2019/02/08/Migration-of-Etcd-to-Masters-for-OpenShift-3.9-Upgrade-to-3.10/</guid><description>As of OpenShift Container Platform 3.10 etcd is expected to run in static pods on the master nodes in the control plane. You may have a deployed an HA cluster with dedicated etcd nodes managed with systemd. How do you migrate the this new architecture?
Assumptions:
You are running OCP 3.9 You have multiple Master nodes You have dedicated Etcd nodes You are running RHEL, not Atomic nodes Outline:
Backup etcd Scale up Etcd cluster to include Master nodes Configure Openshift Masters to ignore the old Etcd nodes Scale down etcd cluster to remove old Etcd nodes Detailed Steps Follow along in this document https://docs.</description></item><item><title>How to Create and Use OpenStack Heat Orchestration Templates Part 1</title><link>http://guifreelife.com/blog/2018/11/21/OpenStack-Heat-Orchestration-Templates-Howto-Part-1/</link><pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2018/11/21/OpenStack-Heat-Orchestration-Templates-Howto-Part-1/</guid><description>OpenStack enables automated creation of resources such as networks, routers, and servers using Heat Orchestration Templates. If you are new to OpenStack and are using a TripleO based distribution you may have seen them up close and personal without knowing it. What follows is a very basic exploration of Heat.
Heat templates are written in YAML format, and you can quickly see from the documentation that a basic template will likely have 4 sections:</description></item><item><title>Creating OpenStack Provider Network for Use by a Single Project</title><link>http://guifreelife.com/blog/2018/10/30/OpenStack-Private-Provider-Network/</link><pubDate>Tue, 30 Oct 2018 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2018/10/30/OpenStack-Private-Provider-Network/</guid><description>OpenStack supports &amp;ldquo;provider&amp;rdquo; networks, which are networks that pre-exist in your physical infrastructure and are &amp;ldquo;provided&amp;rdquo; to the cloud users rather than created by the user. Only an admin is permitted to create a provider network.
A prequisite is the provider network must be plumbed to the external bridge on your controller and nova nodes.
Here is an Ansible playbook to create a project, place a unshared provider network and subnet in that project.</description></item><item><title>Load balancing of OpenShift HA Routers Mind the GARP</title><link>http://guifreelife.com/blog/2018/02/16/OpenShift-Router-LoadBalancing/</link><pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2018/02/16/OpenShift-Router-LoadBalancing/</guid><description>OpenShift HA Routing uses haproxy application routers to get traffic into the cluster. These application routers are made redundant by running ipfailover (keepalived) pods to maintain a set of Virtual IPs on each infrastructure node where the application routers run. These VIPs are then referenced by round robin DNS records to enable a measure of load balancing.
OK, so now you are load balancing at the network layer, but what about the link layer?</description></item><item><title>OpenShift 3.6 Upgrade Metrics Fails Missing heapster-certs Secret</title><link>http://guifreelife.com/blog/2017/10/13/OpenShift-3.6-Upgrade-Metrics-Fails-Missing-heapster-certs-Secret/</link><pubDate>Fri, 13 Oct 2017 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2017/10/13/OpenShift-3.6-Upgrade-Metrics-Fails-Missing-heapster-certs-Secret/</guid><description>After your upgrade to OpenShift v3.6 did the deployment of cluster metrics wind up with empty graphs? Check if the heapster pod failed to start due to a missing secret called heapster-certs in the openshift-infra namespace.
Problem Heapster pod is failing to start
$ oc get pods NAME READY STATUS RESTARTS AGE hawkular-cassandra-1-l1f3s 1/1 Running 0 9m hawkular-metrics-rdl07 1/1 Running 0 9m heapster-cfpcj 0/1 ContainerCreating 0 3m Check what volumes it is attempting to mount</description></item><item><title>Installing OpenShift on OpenStack</title><link>http://guifreelife.com/blog/2017/08/20/OpenShift-on-OpenStack/</link><pubDate>Sun, 20 Aug 2017 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2017/08/20/OpenShift-on-OpenStack/</guid><description>This is a work in progress
The OpenShift Container Platform (OCP) can run on many types of infrastructure; from a Docker contrainer, to a single VM, to a fleet of baremetal or VMs on an infrastructure provider such as RHV, VMware, Amazon EC2, Google Compute Engine, or OpenStack Platform (OSP). This post is to document my experimentation with setting up OCP on OSP.
Doc Overview So where are the docs?</description></item><item><title>OpenStack Network Diagram</title><link>http://guifreelife.com/blog/2017/08/14/OpenStack-Network-Diagram/</link><pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2017/08/14/OpenStack-Network-Diagram/</guid><description>What does the networking for OpenStack look like? Maybe something like this.
# Network VLAN IP CIDR N1 Provisioning (PXE) V:310 172.23.32.0/20 N2 Internal API V:311 172.23.21.0/24 N3 Storage Network (Front) V:312 172.23.22.0/24 N4 Storage Mgmt (Back) V:313 172.23.23.0/24 N5 External Floating IPs V:179 192.0.179.0/24 N6 Public API V:177 192.0.177.0/24 N7 Overcloud Provisioning (Tenant PXE) V:314 172.23.48.0/20 N8 Provider Network (Tenant VM with physical router) V:175 192.0.175.0/24 N9 Tenant Network (tunnels) V:317 172.</description></item><item><title>How to push an image to an unexposed OpenShift Docker registry</title><link>http://guifreelife.com/blog/2017/08/09/Pushing-To-OpenShift-Registry/</link><pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2017/08/09/Pushing-To-OpenShift-Registry/</guid><description>How do I push an image to the OpenShift Docker registry if it is not exposed outside the cluster?
Login to a member node
Get on a machine that has docker and participates in the cluster SDN or can somehow access that network. (eg. 172.30.0.0/16)
Get the IP of the registry
oc get svc docker-registry -n default --template &amp;#34;{{ .spec.clusterIP }}&amp;#34; SVC_REGISTRY=$(oc get svc docker-registry -n default --template &amp;#34;{{ .spec.clusterIP }}&amp;#34;) Get a token for your session</description></item><item><title>Automated Pruning of OpenShift Artifacts; Builds, Deploys, Images</title><link>http://guifreelife.com/blog/2017/03/22/Automated-OpenShift-Artifact-Pruning/</link><pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2017/03/22/Automated-OpenShift-Artifact-Pruning/</guid><description>After running openshift for a while I discovered that letting builds pile up to around to around 1,200 led to what was essentially a deadlock in the scheduling of new builds. New builds were stuck in a New, waiting state indefinitely.
This was fixed as of OCP 3.4.1, but it caused me to get more pro-active in the pruning of artifacts within OpenShift.
I threw together a script and a playbook to deploy it.</description></item><item><title>Configuring OpenShift with Multiple Sharded Routers</title><link>http://guifreelife.com/blog/2017/01/29/OpenShift-Multiple-Sharded-Routers/</link><pubDate>Sun, 29 Jan 2017 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2017/01/29/OpenShift-Multiple-Sharded-Routers/</guid><description>I needed to host a service that would be consumed by a closed client that insists on speaking HTTPS on port 50,000. To solve this, I added a 2nd router deployment and used the OpenShift router sharding feature to selectively enable routes on the 2nd router by way of selectors.
To summarize:
Existing HA router:
HTTP 80 HTTPS 443 Haproxy Stats 1,936 Added HA router:
HTTP 49,999 HTTPS 50,000 Haproxy Stats 51,936 How To Open infra node firewalls Open firewall on infra nodes where router will run to allow new http and https port iptables -A OS_FIREWALL_ALLOW -m tcp -p tcp --dport 49999 -j ACCEPT iptables -A OS_FIREWALL_ALLOW -m tcp -p tcp --dport 50000 -j ACCEPT This can also be done with Ansible and the os_firewall role in your playbook.</description></item><item><title>OpenShift Cluster Metrics and Cassandra Troubleshooting</title><link>http://guifreelife.com/blog/2016/11/14/OpenShift-Cluster-Metrics-and-Cassandra-Troubleshooting/</link><pubDate>Mon, 14 Nov 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/11/14/OpenShift-Cluster-Metrics-and-Cassandra-Troubleshooting/</guid><description>OpenShift gathers cluster metrics such as CPU, memory, and network bandwidth per pod which can assist in troubleshooting and capacity planning. The metrics are also used to support horizontal pod autoscaling, which makes the metrics service not just helpful, but critical to operation.
Missing Liveness Probes There are 3 major components in the metrics collection process. Heapster gathers stats from Docker and feeds them to Hawkular Metrics to tuck away for safe keeping in Cassandra.</description></item><item><title>How to List Tags On Redhat Registry Images</title><link>http://guifreelife.com/blog/2016/07/11/List-Tags-On-Redhat-Registry-Images/</link><pubDate>Mon, 11 Jul 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/07/11/List-Tags-On-Redhat-Registry-Images/</guid><description>Ever gone to RedHat&amp;rsquo;s container registry to search for an image and been left wondering what versions exist? Ever been frustrated by the inconsistent tag format? Is there a v or is there not a v? Me too.
Docker Hub has progressed to v2, while the RedHat registry is still v1 at the moment. As long as you use the right syntax, you can use curl to query the registry API and list the tags like this:</description></item><item><title>Deploy Hawkular Metrics in CDK 2.1 OpenShift 3.2</title><link>http://guifreelife.com/blog/2016/06/16/Deploy-Hawkular-Metrics-in-CDK-2.0-OpenShift-3.1/</link><pubDate>Thu, 16 Jun 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/06/16/Deploy-Hawkular-Metrics-in-CDK-2.0-OpenShift-3.1/</guid><description>Update! I failed with CDK 2.0, but CDK 2.1 works with some fiddling.
In my last post I installed Red Hat Container Developer Kit to deploy OpenShift Enterprise using Vagrant. But now I want to add Hawkular Metrics to that deployment.
Deploy Metrics Refer to the docs for deploying metrics in OSE.
Login to the vagrant CDK VM before continuing
$ cd ~/cdk/components/rhel/rhel-ose/ $ vagrant ssh $ oc login Authentication required for https://127.</description></item><item><title>Getting Started With RedHat Container Development Kit</title><link>http://guifreelife.com/blog/2016/06/16/Getting-Started-With-RedHat-Container-Development-Kit/</link><pubDate>Thu, 16 Jun 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/06/16/Getting-Started-With-RedHat-Container-Development-Kit/</guid><description>The RedHat Container Developer Kit allows you to deploy OpenShift on your laptop for easier testing and development. Here is how to deploy it.
Register as a RedHat Developer Obtain a RH login
Place credentials in ~/.vagrant.d/Vagrantfile to enable updates for VMs by automatically registering with RedHat Subscription Manager
Vagrant.configure(&amp;#39;2&amp;#39;) do |config| config.registration.username = &amp;#39;&amp;lt;your Red Hat username&amp;gt;&amp;#39; config.registration.password = &amp;#39;&amp;lt;your Red Hat password&amp;gt;&amp;#39; end Mac OS X Prereqs Install pre-reqs:</description></item><item><title>Upgrading OpenShift Enterprise from 3.1 to 3.2</title><link>http://guifreelife.com/blog/2016/05/17/OpenShift-Enterprise-Upgrade-3.1-to-3.2/</link><pubDate>Tue, 17 May 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/05/17/OpenShift-Enterprise-Upgrade-3.1-to-3.2/</guid><description>Upgrading from OSE 3.1 to 3.2 using the playbook went quite well for me, but there were a few issues to sort out.
The issues were related to:
ip failover had to be updated manually there was about 5 minutes downtime during the upgrade updates to image streams docker error messages updated policy and role bindings build strategy Source is not allowed hawkular metrics Upgrade Process Following the directions is pretty straight forward.</description></item><item><title>Changing the SSL Certificate for OpenShift Console</title><link>http://guifreelife.com/blog/2016/03/24/Replace-OpenShift-Console-SSL-Certificate/</link><pubDate>Thu, 24 Mar 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/03/24/Replace-OpenShift-Console-SSL-Certificate/</guid><description>OpenShift has an internal CA for generating certificates to authenticate intra-cluster communication, but your browser doesn&amp;rsquo;t trust this CA. Perhaps you want to fix that without mucking with the internal SSL communication? I did. Here is how.
This OpenShift doc explains how to do this, but it isn&amp;rsquo;t very clear, to me at least.
Overview An outline of the steps:
Only make changes to the public URLs and not any internal URLs.</description></item><item><title>OpenShift High Availability - Routing</title><link>http://guifreelife.com/blog/2016/03/01/OpenShift-3-HA-Routing/</link><pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2016/03/01/OpenShift-3-HA-Routing/</guid><description>Highly availabile containers in OpenShift are baked into the cake thanks to replication controllers and service load balancing, but there are plenty of other single points of failure. Here is how to eliminate many of those.
Single Points of Failure The components of OpenShift include:
Master controller manager server and API endpoint Etcd configuration and state storage Docker Registry Router haproxy This post is mostly about adding high availability to the routing layer.</description></item><item><title>Ansible Playbook to Prepare for OpenShift Enterprise 3.1</title><link>http://guifreelife.com/blog/2015/12/12/Playbook-to-Prepare-for-OpenShift-Enterprise-3.1-Install/</link><pubDate>Sat, 12 Dec 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/12/12/Playbook-to-Prepare-for-OpenShift-Enterprise-3.1-Install/</guid><description>This playbook is written for RHEL 7.2 and OSE v3.1. It will perform the following steps which should take place before running the openshift-ansible byo playbook.
Install prerequisite RPMs like docker, python, etc. Persist the systemd journal for easier debugging Setup docker ephemeral storage on 2nd disk Turn off swap Enable use of NFS in selinux Prerequisites See my Testing OpenShift Enterprise V3 post for the prereqs.
The Playbook The lastest version is available here.</description></item><item><title>Ansible CMDB Inventory and Facts Reporting</title><link>http://guifreelife.com/blog/2015/12/06/Ansible-CMDB-Inventory-and-Facts-Reporting/</link><pubDate>Sun, 06 Dec 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/12/06/Ansible-CMDB-Inventory-and-Facts-Reporting/</guid><description>You just deployed a complex multi-host app using Ansible. Wouldn&amp;rsquo;t it be helpful to see a overview of the deployment including hardware details?
I just found ansible-cmdb which combines info from the Ansible inventory and discovered facts to create a detailed HTML report akin to a Configuration Management Database.
To use it in your playbook dir, just create a directory to hold facts discovered by the setup module then generate the report.</description></item><item><title>Notes on SNMP MIBs OIDs and Grey Whiskers</title><link>http://guifreelife.com/blog/2015/09/08/SNMP-OIDs/</link><pubDate>Tue, 08 Sep 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/09/08/SNMP-OIDs/</guid><description>With as many grey whiskers as I have, you would think I could grok SNMP in my sleep by now. Unfortunately, everytime I have to deal with it I get frustrated, wonder where the hell my notes from last time are, and start cursing. From now on, here are my notes!
I&amp;rsquo;m typically using Zabbix to poll SNMP OIDs and place the MIBs on the Zabbix server or the Zabbix proxy responsible for SNMP in /usr/share/snmp/mibs.</description></item><item><title>Testing OpenShift Enterprise V3</title><link>http://guifreelife.com/blog/2015/07/28/Testing-OpenShift-Enterprise-V3/</link><pubDate>Tue, 28 Jul 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/07/28/Testing-OpenShift-Enterprise-V3/</guid><description>So much for testing OpenShift Origin with Vagrant on OS X, because it does not work yet. Let&amp;rsquo;s evaluate OpenShift Enterprise v3 on RHEL! First go get yourself an eval license. The OpenShift VMs will run RHEL7.1 and ride on top of RHEV.
Documentation First off, here are some starting points to get oriented and acquainted with OpenShift.
Docs
Getting Started Docs Overview Training Download Prerequisites OpenShift Enterprise 3 Architecture Guide - planning, deployment and operation of an Open Source Platform as a Service Load Balancing Videos</description></item><item><title>Testing Openshift Origin V3 with Ansible and Vagrant on OS X</title><link>http://guifreelife.com/blog/2015/06/28/Testing-Openshift-Origin-V3-with-Ansible-and-Vagrant-on-OS-X/</link><pubDate>Sun, 28 Jun 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/06/28/Testing-Openshift-Origin-V3-with-Ansible-and-Vagrant-on-OS-X/</guid><description>The OpenShift Origin project provides Ansible playbooks and roles for installing OpenShift on various infratructure. I&amp;rsquo;m going to try out the example using Vagrant and VirtualBox on my Mac. I&amp;rsquo;m not very familiar with Vagrant or OpenShift v3 yet, so I&amp;rsquo;m just going to think out loud and see how it goes. I&amp;rsquo;ve also recently started testing OpenShift Enterprise.
Some Background OpenShift Origin is an opensource PaaS (platform as a service).</description></item><item><title>How To Scale Up Ansible Playbooks and Roles in a Managable Way</title><link>http://guifreelife.com/blog/2015/05/16/Manage-Ansible-Playbooks-and-Roles/</link><pubDate>Sat, 16 May 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/05/16/Manage-Ansible-Playbooks-and-Roles/</guid><description>Ansible is Awesome! Ansible is a Mess! So you found Ansible, and you were all Woah! Ansible is awesome! Ansibilize all the things! Then you created a git repo and started hacking.
Playbooks look in the current directory to find roles, libraries, and inventories, so naturally you put everything in one big git repo, right?
You tried to follow the best practices for writing playbooks, you created roles, and maybe you wrote a filter plugin or a custom module for configuring an application unique to your environment.</description></item><item><title>Resources for Learning About Docker</title><link>http://guifreelife.com/blog/2015/04/19/Resources-for-Learning-Docker/</link><pubDate>Sun, 19 Apr 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/04/19/Resources-for-Learning-Docker/</guid><description>Tutorials Docker&amp;rsquo;s 10min Tutorial
Andrew Baker&amp;rsquo;s Introduction to Docker
Red Hat Workhops
Docker and Kubernetes Training - Christian Posta Blog
Intro Day 1 Day 2 Day 3 Day 4 Books As of April 2015, O&amp;rsquo;Reilly has at least 3 books on Docker pending publication. The first two are available in pre-release form now.
Using Docker My exercises from the book: identidock Docker Cookbook Docker: Up and Running Blogs Docker Blog Docker Weekly Newsletter Rancher Blog posts some great overviews like this one and this one on monitoring ClusterHQ Blog from makers of Flocker container live migration Videos O&amp;rsquo;Reilly Introduction to Docker</description></item><item><title>Split an Ansible Git Repo and Retain the Commit History</title><link>http://guifreelife.com/blog/2015/03/15/Split-Ansible-Git-Repo-and-Retain-Commit-History/</link><pubDate>Sun, 15 Mar 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/03/15/Split-Ansible-Git-Repo-and-Retain-Commit-History/</guid><description>Starting with a jumbled git repo of various Ansible roles, playbooks, inventories, group_vars, etc. I want to create a new repo out of a selection of the subdirectories and retain the commit history.
I have an ansible-test repo with a tree that looks roughly like this:
. ├── adhoc/ │ ├── rolling-reboot.yml │ └── scripts/ ├── README.md └── runtime/ ├── roles/ │ ├── foo-role/ │ └── zimbra/ │ ├── ansible.cfg │ ├── hosts │ ├── tasks/ │ └── .</description></item><item><title>Zimbra Exchange Web Services Crashes OS X Mail.app</title><link>http://guifreelife.com/blog/2015/02/17/Zimbra-Exchange-Web-Services-Crashes-OS-X-Mail.app/</link><pubDate>Tue, 17 Feb 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/02/17/Zimbra-Exchange-Web-Services-Crashes-OS-X-Mail.app/</guid><description>Zimbra added EWS support in ZCS 8.5. Right around that time OS X 10.10 was released. Cool! Let&amp;rsquo;s start syncing all our things to our brand new Mail.app, Calendar.app, and Contacts.app over HTTPS!
Strangely, this page says that:
ZCS 8.5 targeted EWS support ONLY with Outlook for Mac&amp;rsquo;s. There was no testing or expectation that the native mac apps would work with the EWS configuration type.
Really?! I hope that&amp;rsquo;s not true.</description></item><item><title>Tuning ext4 Creation and Mount Options for Zimbra</title><link>http://guifreelife.com/blog/2015/02/02/Ext4-Tuning-and-Mount-Options-for-Zimbra/</link><pubDate>Mon, 02 Feb 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/02/02/Ext4-Tuning-and-Mount-Options-for-Zimbra/</guid><description>Zimbra is a email collaboration suite. Its various compontents perform MTA duties, message store, full text indexing. In a large environment, the number of files and I/O operations can really add up. How we ensure the filesystem is ready to support it?
Zimbra&amp;rsquo;s Recommendations Zimbra offers some guidance for tuning the filesystem, with tips like:
Mount file systems with the noatime option.
It generally is not important to know the last access time of all the files, so the extra write ops are wasteful.</description></item><item><title>Using Ansible Filters to Customize the Order Of Hosts in a List</title><link>http://guifreelife.com/blog/2015/02/01/Ansible-Customizing-Order-Of-Hosts-in-List/</link><pubDate>Sun, 01 Feb 2015 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2015/02/01/Ansible-Customizing-Order-Of-Hosts-in-List/</guid><description>Zimbra is a email / collaboration suite that is typically deployed in a cluster or clusters of dedicated servers which fill roles like LDAP master, LDAP replica, Proxy, MTA, Mailstore, etc.
The LDAP servers are used by all the other servers to store configuration and provisioning data. Servers in the cluster understand where to find the LDAP master (read/write) and LDAP replicas (read only) though values defined in /opt/zimbra/conf/localconfig.xml.
There are 2 values relevant to LDAP server lists and they have values like this:</description></item><item><title>Openshift V2 and Flask with Virtualenv on OS X</title><link>http://guifreelife.com/blog/2014/11/22/Openshift-and-Flask-with-Virtualenv-on-OS-X/</link><pubDate>Sat, 22 Nov 2014 00:00:00 +0000</pubDate><guid>http://guifreelife.com/blog/2014/11/22/Openshift-and-Flask-with-Virtualenv-on-OS-X/</guid><description>Create a flask app for Openshift with a matching local python virtualenv to perform local testing.
In this case we&amp;rsquo;ll use Python 2.7 on Mac OS X 10.9.
Overview of the steps Install Homebrew Install Python Development Environment on Mac OS X Install rhc client tools. Install and Configure a Python Flask for OpenShift Installing Homebrew Ready the system for Homebrew First unhide ~/Library folder.
Open Finder Press shift-command-H Press command-J Check Show Library Folder Now Setup shell environment Some of these settings are only relevant to later steps, but go ahead and put them all in now.</description></item></channel></rss>