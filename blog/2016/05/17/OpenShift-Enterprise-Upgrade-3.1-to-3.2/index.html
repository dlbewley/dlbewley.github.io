<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta name=viewport content="width=device-width,initial-scale=1"><title>Upgrading OpenShift Enterprise from 3.1 to 3.2</title><meta name=author content="DevCows"><meta name=keywords content="devows,hugo,go,kubernetes,openshift,OSE3,upgrade"><meta name=description content="Site template made by devcows using hugo"><meta name=generator content="Hugo 0.81.0"><link href="//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800" rel=stylesheet type=text/css><link rel=stylesheet href=//use.fontawesome.com/releases/v5.11.2/css/all.css><link rel=stylesheet href=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link href=/css/animate.css rel=stylesheet><link href=/css/style.turquoise.css rel=stylesheet id=theme-stylesheet><link href=/css/custom.css rel=stylesheet><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel="shortcut icon" href=/img/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link href=/css/owl.carousel.css rel=stylesheet><link href=/css/owl.theme.css rel=stylesheet><link rel=alternate href=https://dwnwrd.github.io/index.xml type=application/rss+xml title="dwnwrd Universal"><meta property="og:locale" content="en_us"><meta property="og:site_name" content="dwnwrd Universal"><meta property="og:title" content="Upgrading OpenShift Enterprise from 3.1 to 3.2"><meta property="og:type" content="article"><meta property="og:url" content="https://dwnwrd.github.io/blog/2016/05/17/OpenShift-Enterprise-Upgrade-3.1-to-3.2/"><meta property="og:description" content="Site template made by devcows using hugo"><meta property="og:image" content="https://dwnwrd.github.io/img/banners/banner-16.jpg"><meta property="og:image:type" content="image/jpg"><meta property="og:image:width" content="563"><meta property="og:image:height" content="750"><meta property="og:updated_time" content="2016-05-17T00:00:00Z"><meta property="article:tag" content="kubernetes"><meta property="article:tag" content="openshift"><meta property="article:tag" content="OSE3"><meta property="article:tag" content="upgrade"><meta property="article:published_time" content="2016-05-17T00:00:00Z"><meta property="article:modified_time" content="2016-05-17T00:00:00Z"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@dlbewley"><meta name=twitter:title content="Upgrading OpenShift Enterprise from 3.1 to 3.2"><meta name=twitter:image content="https://dwnwrd.github.io/img/banners/banner-16.jpg"><meta name=twitter:description content="Site template made by devcows using hugo"></head><body><div id=all><header class=navbar-affixed-top data-spy=affix data-offset-top=62><div class="navbar navbar-default yamm" role=navigation id=navbar><div class=container><div class=navbar-header><a class="navbar-brand home" href=/><img src=/img/logo.png alt="Upgrading OpenShift Enterprise from 3.1 to 3.2 logo" class="hidden-xs hidden-sm">
<img src=/img/logo-small.png alt="Upgrading OpenShift Enterprise from 3.1 to 3.2 logo" class="visible-xs visible-sm">
<span class=sr-only>Upgrading OpenShift Enterprise from 3.1 to 3.2 - go to homepage</span></a><div class=navbar-buttons><button type=button class="navbar-toggle btn-template-main" data-toggle=collapse data-target=#navigation>
<span class=sr-only>Toggle Navigation</span>
<i class="fas fa-align-justify"></i></button></div></div><div class="navbar-collapse collapse" id=navigation><ul class="nav navbar-nav navbar-right"><li class=dropdown><a href=/>Home</a></li><li class="dropdown active"><a href=/blog/>Blog</a></li><li class=dropdown><a href=/contact/>Contact</a></li></ul></div><div class="collapse clearfix" id=search><form class=navbar-form role=search><div class=input-group><input type=text class=form-control placeholder=Search>
<span class=input-group-btn><button type=submit class="btn btn-template-main"><i class="fas fa-search"></i></button></span></div></form></div></div></div></header><div id=heading-breadcrumbs><div class=container><div class=row><div class=col-md-12><h1>Upgrading OpenShift Enterprise from 3.1 to 3.2</h1></div></div></div></div><div id=content><div class=container><div class=row><div class=col-md-9 id=blog-post><p class="text-muted text-uppercase mb-small text-right">May 17, 2016</p><div id=post-content><p>Upgrading from OSE 3.1 to 3.2 using the <a href=https://github.com/openshift/openshift-ansible/blob/master/playbooks/common/openshift-cluster/upgrades/v3_1_to_v3_2/upgrade.yml>playbook</a> went quite well for me, but there were a few issues to sort out.</p><p>The issues were related to:</p><ul><li><a href=#ip-failover>ip failover</a> had to be updated manually</li><li>there was about 5 minutes <a href=#downtime-during-upgrade>downtime during the upgrade</a></li><li><a href=#image-stream-updates>updates to image streams</a></li><li><a href=#docker-errors>docker error messages</a></li><li><a href=#update-cluster-policies-and-roles>updated policy and role bindings</a> <em>build strategy Source is not allowed</em></li><li><a href=#hawkular-metrics>hawkular metrics</a></li></ul><h1 id=upgrade-process>Upgrade Process</h1><p>Following the directions is pretty straight forward.</p><ul><li>Start by prepping the yum repos.</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
<span style=color:#75715e># file: upgrade-prep.yml</span>
<span style=color:#75715e># </span>
<span style=color:#75715e># After running this see:</span>
<span style=color:#75715e># - https://docs.openshift.com/enterprise/latest/install_config/upgrading/automated_upgrades.html</span>
<span style=color:#75715e># - https://docs.openshift.com/enterprise/latest/install_config/upgrading/manual_upgrades.html</span>

- <span style=color:#f92672>hosts</span>: <span style=color:#ae81ff>all</span>
  <span style=color:#f92672>gather_facts</span>: <span style=color:#66d9ef>yes</span>

  <span style=color:#f92672>vars</span>:
    <span style=color:#f92672>ose_ver_old</span>: <span style=color:#ae81ff>3.1</span>
    <span style=color:#f92672>ose_ver_new</span>: <span style=color:#ae81ff>3.2</span>

  <span style=color:#f92672>tasks</span>:

  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>enable yum repos for upgrade version</span>
    <span style=color:#f92672>command</span>: <span style=color:#e6db74>&#39;/usr/sbin/subscription-manager repos --disable=&#34;rhel-7-server-ose-{{ose_ver_old}}-rpms&#34; --enable=&#34;rhel-7-server-ose-{{ose_ver_new}}-rpms&#34;&#39;</span>

  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>update openshift-utils</span>
    <span style=color:#f92672>yum</span>:
      <span style=color:#f92672>name</span>: <span style=color:#ae81ff>atomic-openshift-utils</span>
      <span style=color:#f92672>state</span>: <span style=color:#ae81ff>latest</span>
</code></pre></div><ul><li>Then run the upgrade</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>ansible-playbook -i hosts openshift-ansible/playbooks/byo/openshift-cluster/upgrades/v3_1_to_v3_2/upgrade.yml | <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>  tee ansible-upgrade-<span style=color:#66d9ef>$(</span>date +%Y%m%d-%H%M<span style=color:#66d9ef>)</span>.log
</code></pre></div><ul><li></li></ul><h1 id=ip-failover>IP Failover</h1><p>I previously described the <a href=/blog/2016/03/01/OpenShift-3-HA-Routing>native HA routing I am using</a>.</p><p><strong>Basically:</strong></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc get nodes -l <span style=color:#e6db74>&#34;region=infra&#34;</span>
NAME                           STATUS                     AGE
ose-prod-master-01.example.com   Ready,SchedulingDisabled   71d
ose-prod-master-02.example.com   Ready,SchedulingDisabled   71d
ose-prod-master-03.example.com   Ready,SchedulingDisabled   71d
ose-prod-node-01.example.com     Ready                      71d
ose-prod-node-02.example.com     Ready                      71d
ose-prod-node-03.example.com     Ready                      71d

$ oc scale --replicas<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span> dc router

$ oadm router ha-router-primary <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --replicas<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;ha-router=primary&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;region=infra&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --labels<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;ha-router=primary&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --credentials<span style=color:#f92672>=</span>/etc/origin/master/openshift-router.kubeconfig <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --default-cert<span style=color:#f92672>=</span>201602_router_wildcard.os.example.com.pem <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --service-account<span style=color:#f92672>=</span>router

$ oadm ipfailover ipf-ha-router-primary <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --replicas<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --watch-port<span style=color:#f92672>=</span><span style=color:#ae81ff>80</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;ha-router=primary&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --virtual-ips<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;192.0.2.101-103&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --credentials<span style=color:#f92672>=</span>/etc/origin/master/openshift-router.kubeconfig <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --service-account<span style=color:#f92672>=</span>router <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --create
</code></pre></div><h2 id=ipf-image>IPF Image</h2><p>The upgrade playbook updated the image used by the default router dc, but since I use Native HA with IPfailover I do not use that router. Mine is called <code>ha-router-primary</code>. I was able to manually update the image for <code>ha-router-primary</code> as described <a href=https://docs.openshift.com/enterprise/3.2/install_config/upgrading/manual_upgrades.html#upgrading-the-router>here</a>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc get dc -n default
NAME                    TRIGGERS       LATEST
docker-registry         ConfigChange   <span style=color:#ae81ff>3</span>
ha-router-primary       ConfigChange   <span style=color:#ae81ff>2</span>
ipf-ha-router-primary   ConfigChange   <span style=color:#ae81ff>1</span>
router                  ConfigChange   <span style=color:#ae81ff>3</span>      &lt;-- unused. <span style=color:#ae81ff>0</span> replicas.

$ oc get dc ha-router-primary -n default -o json | jq <span style=color:#e6db74>&#39;. | {name: .spec.template.spec.containers[].name, image: .spec.template.spec.containers[].image}&#39;</span>
<span style=color:#f92672>{</span>
  <span style=color:#e6db74>&#34;image&#34;</span>: <span style=color:#e6db74>&#34;openshift3/ose-haproxy-router:v3.2.0.20-3&#34;</span>,
  <span style=color:#e6db74>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;router&#34;</span>
<span style=color:#f92672>}</span>
$ oc get dc ipf-ha-router-primary -n default -o json | jq <span style=color:#e6db74>&#39;. | {name: .spec.template.spec.containers[].name, image: .spec.template.spec.containers[].image}&#39;</span>
<span style=color:#f92672>{</span>
  <span style=color:#e6db74>&#34;image&#34;</span>: <span style=color:#e6db74>&#34;openshift3/ose-keepalived-ipfailover:v3.1.1.6&#34;</span>,
  <span style=color:#e6db74>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;ipf-ha-router-primary-keepalived&#34;</span>
<span style=color:#f92672>}</span>
</code></pre></div><p>However, that leaves the ipfailover pods still at <code>v3.1.1.6</code>. Presumably it should use <code>v3.2.0.20-3</code>, but I&rsquo;m not sure how to validate that.</p><ul><li><p><strong>What image tag should I use for the <code>openshift3/ose-keepalived-ipfailover</code> image?</strong></p></li><li><p><strong>How can I enumerate the tags to find this on my own?</strong></p></li></ul><p>Well, I can go search <a href=https://access.redhat.com/search/#/container-images>registry.access.redhat.com</a>, but the results don&rsquo;t list the version tags. Trying a <code>docker pull openshift3/ose-keepalived-ipfailover:v3.2.0.20-3</code> works, so let&rsquo;s do it. The <a href=https://github.com/openshift/origin/blob/master/docs/cli.md#oc-patch>oc patch</a> command makes this &ldquo;easy&rdquo; if you like counting braces.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc patch dc ipf-ha-router-primary -p <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span> <span style=color:#e6db74>&#39;{&#34;spec&#34;: {&#34;template&#34;: {&#34;spec&#34;: {&#34;containers&#34;: [{&#34;name&#34;: &#34;ipf-ha-router-primary-keepalived&#34;, &#34;image&#34;: &#34;openshift3/ose-keepalived-ipfailover:v3.2.0.20-3&#34;}]}}}}&#39;</span>
</code></pre></div><p>When the change is made it will be detected and the ipfailover pods will be recreated automatically. I didn&rsquo;t detect any downtime when doing this.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc get dc ipf-ha-router-primary -n default -o json | jq <span style=color:#e6db74>&#39;. | {name: .spec.template.spec.containers[].name, image: .spec.template.spec.containers[].image}&#39;</span>
<span style=color:#f92672>{</span>
  <span style=color:#e6db74>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;ipf-ha-router-primary-keepalived&#34;</span>,
  <span style=color:#e6db74>&#34;image&#34;</span>: <span style=color:#e6db74>&#34;openshift3/ose-keepalived-ipfailover:v3.2.0.20-3&#34;</span>
<span style=color:#f92672>}</span>
</code></pre></div><p>On a related note, I&rsquo;m hoping to see <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1324594">this bugzilla</a> integrated into the keepalived image soon, so <a href=https://sysdig.com/>Sysdig</a> can be used on the infra nodes.</p><h2 id=ipfailover-readiness-check>IPfailover Readiness Check</h2><p>The <code>oc status -v</code> command tells me I have no readiness check for my <code>ipf-ha-router-primary</code> dc. The <a href=https://docs.openshift.com/enterprise/3.2/admin_guide/high_availability.html>docs</a> however do not mention a suitable check for ipfailover.</p><ul><li><strong>Is there a suitable readiness check for ipfailover service?</strong></li></ul><pre><code>Warnings:
  * dc/docker-registry has no readiness probe to verify pods are ready to accept traffic or ensure deployment is successful.
    try: oc set probe dc/docker-registry --readiness ...
  * dc/ipf-ha-router-primary has no readiness probe to verify pods are ready to accept traffic or ensure deployment is successful.
    try: oc set probe dc/ipf-ha-router-primary --readiness ...
</code></pre><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc get dc/ipf-ha-router-primary
NAME                    REVISION   REPLICAS   TRIGGERED BY
ipf-ha-router-primary   <span style=color:#ae81ff>1</span>          <span style=color:#ae81ff>3</span>          config

$ oc describe dc/ipf-ha-router-primary
Name:           ipf-ha-router-primary
Created:        <span style=color:#ae81ff>10</span> weeks ago
Labels:         ha-router<span style=color:#f92672>=</span>primary
Annotations:    &lt;none&gt;
Latest Version: <span style=color:#ae81ff>1</span>
Selector:       ha-router<span style=color:#f92672>=</span>primary
Replicas:       <span style=color:#ae81ff>3</span>
Triggers:       Config
Strategy:       Recreate
Template:
  Labels:               ha-router<span style=color:#f92672>=</span>primary
  Service Account:      router
  Containers:
  ipf-ha-router-primary-keepalived:
    Image:      openshift3/ose-keepalived-ipfailover:v3.1.1.6
    Port:       1985/TCP
    QoS Tier:
      memory:   BestEffort
      cpu:      BestEffort
    Environment Variables:
      OPENSHIFT_CA_DATA:        -----BEGIN CERTIFICATE-----
...
WgXt+xTlODyXtB9CmeGWK+dqH3M8AgfRUJQ<span style=color:#f92672>=</span>
-----END CERTIFICATE-----

      OPENSHIFT_CERT_DATA:      -----BEGIN CERTIFICATE-----
...
MWdnBMd2iCXSsVJIafxc60o<span style=color:#f92672>=</span>
-----END CERTIFICATE-----

      OPENSHIFT_HA_CONFIG_NAME:         ipf-ha-router-primary
      OPENSHIFT_HA_MONITOR_PORT:        <span style=color:#ae81ff>80</span>
      OPENSHIFT_HA_NETWORK_INTERFACE:
      OPENSHIFT_HA_REPLICA_COUNT:       <span style=color:#ae81ff>3</span>
      OPENSHIFT_HA_USE_UNICAST:         false
      OPENSHIFT_HA_VIRTUAL_IPS:         192.0.2.101-103
      OPENSHIFT_INSECURE:               false
      OPENSHIFT_KEY_DATA:               -----BEGIN RSA PRIVATE KEY-----
...
xO/p48yGpN1JeqBQy7mlFQAIn1/4vBvfnjc/rljeqn19u01NuGkqJQ<span style=color:#f92672>==</span>
-----END RSA PRIVATE KEY-----

      OPENSHIFT_MASTER: https://master.os.example.com:8443
  Volumes:
  lib-modules:
    Type:       HostPath <span style=color:#f92672>(</span>bare host directory volume<span style=color:#f92672>)</span>
    Path:       /lib/modules

Deployment <span style=color:#75715e>#1 (latest):</span>
        Name:           ipf-ha-router-primary-1
        Created:        <span style=color:#ae81ff>10</span> weeks ago
        Status:         Complete
        Replicas:       <span style=color:#ae81ff>3</span> current / <span style=color:#ae81ff>3</span> desired
        Selector:       deployment<span style=color:#f92672>=</span>ipf-ha-router-primary-1,deploymentconfig<span style=color:#f92672>=</span>ipf-ha-router-primary,ha-router<span style=color:#f92672>=</span>primary
        Labels:         ha-router<span style=color:#f92672>=</span>primary,openshift.io/deployment-config.name<span style=color:#f92672>=</span>ipf-ha-router-primary
        Pods Status:    <span style=color:#ae81ff>3</span> Running / <span style=color:#ae81ff>0</span> Waiting / <span style=color:#ae81ff>0</span> Succeeded / <span style=color:#ae81ff>0</span> Failed

No events.
</code></pre></div><h2 id=downtime-during-upgrade>Downtime During Upgrade</h2><p>The upgrade playbook ran fine from ose-prod-master-01 and took 11:49. I used the latest upstream playbook cloned <a href=https://github.com/openshift/openshift-ansible>from Github</a> rather than from <code>/usr/share/ansible/openshift-ansible</code>. Output is attached.</p><pre><code>localhost                  : ok=44   changed=0    unreachable=0    failed=0
ose-prod-etcd-01.example.com : ok=47   changed=4    unreachable=1    failed=0
ose-prod-etcd-02.example.com : ok=47   changed=4    unreachable=1    failed=0
ose-prod-etcd-03.example.com : ok=47   changed=4    unreachable=1    failed=0
ose-prod-lb-01.example.com   : ok=26   changed=2    unreachable=0    failed=0
ose-prod-master-01.example.com : ok=263  changed=39   unreachable=0    failed=0
ose-prod-master-02.example.com : ok=217  changed=34   unreachable=0    failed=0
ose-prod-master-03.example.com : ok=215  changed=31   unreachable=0    failed=0
ose-prod-node-01.example.com : ok=126  changed=20   unreachable=0    failed=0
ose-prod-node-02.example.com : ok=126  changed=20   unreachable=0    failed=0
ose-prod-node-03.example.com : ok=126  changed=20   unreachable=0    failed=0
ose-prod-node-04.example.com : ok=126  changed=20   unreachable=0    failed=0
ose-prod-node-05.example.com : ok=126  changed=20   unreachable=0    failed=0
ose-prod-node-06.example.com : ok=124  changed=17   unreachable=0    failed=0

real    11m49.852s
user    1m30.466s
sys     0m49.686s
</code></pre><p>During upgrade playbook run, I had pings going to my ipfailover VIPs each second. (<code>fping -l -p1000 &lt; routers</code>). I saw 300 seconds of ping fails during upgrade.</p><ul><li><strong>Is there no way to avoid downtime of the router VIPs during upgrade?</strong></li></ul><pre><code>192.0.2.101 : xmt/rcv/%loss = 1497/1174/21%, min/avg/max = 0.14/0.31/84.1
192.0.2.102 : xmt/rcv/%loss = 1497/1181/21%, min/avg/max = 0.11/0.28/43.6
192.0.2.103 : xmt/rcv/%loss = 1497/1198/19%, min/avg/max = 0.12/0.27/22.0
</code></pre><h1 id=image-stream-updates>Image Stream Updates</h1><p>I still see 3.1.1 referenced by several images, and I&rsquo;m still working out how to deduce the right image to use and to update them.</p><ul><li><strong>How do I update all OSE 3.1.1 vintage images?</strong></li></ul><pre><code>[root@ose-prod-node-05 ~]# docker images | grep 3.1.1
registry.access.redhat.com/openshift3/ose-docker-builder         v3.1.1.6            aefb1274aacc        6 weeks ago         442 MB
registry.access.redhat.com/openshift3/metrics-heapster           3.1.1               2ff00fc36375        10 weeks ago        230 MB
registry.access.redhat.com/openshift3/metrics-hawkular-metrics   3.1.1               5c02894a36cd        10 weeks ago        1.435 GB
registry.access.redhat.com/openshift3/metrics-cassandra          3.1.1               12d617a9aa1c        10 weeks ago        523 MB
registry.access.redhat.com/openshift3/ose-sti-builder            v3.1.1.6            75fa4984985a        11 weeks ago        441.9 MB
registry.access.redhat.com/openshift3/ose-deployer               v3.1.1.6            3bcee4233589        11 weeks ago        441.9 MB
registry.access.redhat.com/openshift3/ose-pod                    v3.1.1.6            ecfbff48161c        11 weeks ago        427.9 MB
</code></pre><h1 id=docker-errors>Docker Errors</h1><ul><li><strong>When with <em>get pwuid struct: user: unknown userid</em> errors be fixed?</strong></li></ul><p>I am seeing the following error repeatedly:</p><pre><code>May 17 11:33:23 ose-prod-node-05.example.com forward-journal[33427]: time=&quot;2016-05-17T11:33:23.255421438-07:00&quot; level=error msg=&quot;Failed to get pwuid struct: user: unknown userid 4294967295&quot;
May 17 11:33:23 ose-prod-node-05.example.com forward-journal[33427]: time=&quot;2016-05-17T11:33:23.263135054-07:00&quot; level=error msg=&quot;Failed to get pwuid struct: user: unknown userid 4294967295&quot;
May 17 11:33:23 ose-prod-node-05.example.com forward-journal[33427]: time=&quot;2016-05-17T11:33:23.283089775-07:00&quot; level=error msg=&quot;Failed to get pwuid struct: user: unknown userid 4294967295&quot;
May 17 11:33:23 ose-prod-node-05.example.com forward-journal[33427]: time=&quot;2016-05-17T11:33:23.696824533-07:00&quot; level=error msg=&quot;Failed to get pwuid struct: user: unknown userid 4294967295&quot;
May 17 11:33:23 ose-prod-node-05.example.com forward-journal[33427]: time=&quot;2016-05-17T11:33:23.959131064-07:00&quot; level=error msg=&quot;Failed to get pwuid struct: user: unknown userid 4294967295&quot;
May 17 11:33:23 ose-prod-node-05.example.com forward-journal[33427]: time=&quot;2016-05-17T11:33:23.994201790-07:00&quot; level=error msg=&quot;Failed to get pwuid struct: user: unknown userid 4294967295&quot;
</code></pre><p>This is even though <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1275399">BZ#1275399</a> indicates this was fixed by <a href=https://rhn.redhat.com/errata/RHBA-2016-0536.html>Errata RHBA-2016-0536</a></p><p>Wait, I still have the issue after an upgrade to OSE 3.2.0 and docker-1.9.1-40.el7.x86_64. <a href=https://github.com/projectatomic/docker/pull/156>This PR</a> mentioned by <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1335635">BZ#1335635</a> indicates the fix should have been in Docker 1.9.1-40 and is coming in 1.10.</p><h1 id=update-cluster-policies-and-roles>Update Cluster Policies and Roles</h1><p>Run <code>oadm diagnostics</code> to do some sanity checks. Some results should be taken with a grain of salt.</p><p>Cluster policies and roles changed, so update them to the latest. To see what needs to change run <code>oadm policy reconcile-cluster-roles</code> and <code>oadm policy reconcile-cluster-role-bindings</code>.
See <a href=https://docs.openshift.com/enterprise/3.2/install_config/upgrading/manual_upgrades.html#updating-policy-definitions>the docs</a>.</p><p>The <a href=https://github.com/openshift/openshift-docs/issues/2131>docs say</a> to restart <code>atomic-openshift-master</code>, but I think that should `atomic-openshift-master-api</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#75715e># examine output before continuing</span>
$ oadm policy reconcile-cluster-roles
<span style=color:#75715e># make the changes suggested by above on one master</span>
$ oadm policy reconcile-cluster-roles  --confirm
<span style=color:#75715e># restart api on all masters</span>
$ systemctl restart atomic-openshift-master-api
<span style=color:#75715e># update policy role bindings</span>
$ oadm policy reconcile-cluster-role-bindings <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --exclude-groups<span style=color:#f92672>=</span>system:authenticated <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --exclude-groups<span style=color:#f92672>=</span>system:authenticated:oauth <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --exclude-groups<span style=color:#f92672>=</span>system:unauthenticated <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --exclude-users<span style=color:#f92672>=</span>system:anonymous <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --additive-only<span style=color:#f92672>=</span>true <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --confirm
</code></pre></div><p>Even after this I&rsquo;m seeing these warnings from <code>oadm diagnostics</code>, and developers can no longer use the source build strategy. Big problem.</p><pre><code>$ oadm diagnostics
...
[Note] Running diagnostic: ClusterRoleBindings
       Description: Check that the default ClusterRoleBindings are present and contain the expected subjects

Info:  clusterrolebinding/cluster-admins has more subjects than expected.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to remove extra subjects.

Info:  clusterrolebinding/cluster-admins has extra subject {User  dlbewley    }.

Info:  clusterrolebinding/cluster-readers has more subjects than expected.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to remove extra subjects.

Info:  clusterrolebinding/cluster-readers has extra subject {ServiceAccount management-infra management-admin    }.
Info:  clusterrolebinding/cluster-readers has extra subject {ServiceAccount openshift-infra heapster    }.
Info:  clusterrolebinding/cluster-readers has extra subject {User  sysdig    }.
Info:  clusterrolebinding/cluster-readers has extra subject {ServiceAccount openshift-infra sysdig    }.

WARN:  [CRBD1003 from diagnostic ClusterRoleBindings@openshift/origin/pkg/diagnostics/cluster/rolebindings.go:83]
       clusterrolebinding/self-provisioners is missing expected subjects.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to include expected subjects.

Info:  clusterrolebinding/self-provisioners is missing subject {SystemGroup  system:authenticated:oauth    }.
Info:  clusterrolebinding/self-provisioners has extra subject {SystemGroup  system:authenticated    }.

WARN:  [CRBD1003 from diagnostic ClusterRoleBindings@openshift/origin/pkg/diagnostics/cluster/rolebindings.go:83]
       clusterrolebinding/system:build-strategy-docker-binding is missing expected subjects.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to include expected subjects.

Info:  clusterrolebinding/system:build-strategy-docker-binding is missing subject {SystemGroup  system:authenticated    }.

WARN:  [CRBD1003 from diagnostic ClusterRoleBindings@openshift/origin/pkg/diagnostics/cluster/rolebindings.go:83]
       clusterrolebinding/system:build-strategy-custom-binding is missing expected subjects.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to include expected subjects.

Info:  clusterrolebinding/system:build-strategy-custom-binding is missing subject {SystemGroup  system:authenticated    }.

WARN:  [CRBD1003 from diagnostic ClusterRoleBindings@openshift/origin/pkg/diagnostics/cluster/rolebindings.go:83]
       clusterrolebinding/system:build-strategy-source-binding is missing expected subjects.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to include expected subjects.

Info:  clusterrolebinding/system:build-strategy-source-binding is missing subject {SystemGroup  system:authenticated    }.
</code></pre><p>Rather than try to fix each of the above, I&rsquo;ve been trying to work with RedHat support to try to understand the correct way to fix it.</p><p>By comparing the output of <code>oc describe clusterPolicyBindings :default</code> on 3.1.1 and 3.2.0 you can see these new RoleBindings</p><pre><code>RoleBinding[system:build-strategy-custom-binding]:
RoleBinding[system:build-strategy-docker-binding]:
RoleBinding[system:build-strategy-source-binding]:
RoleBinding[system:discovery-binding]:
</code></pre><p>It makes sense that the reconcile command should not exclude the <code>system:authenticated</code> users as the docs say to do.</p><ul><li>Save the output beforehand</li></ul><pre><code>oc describe clusterPolicyBindings :default &gt; describe-clusterPolicyBindings-default-before.txt
</code></pre><ul><li>Reconcile the role bindings again but do not exclude <code>system:authenticated</code></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oadm policy reconcile-cluster-role-bindings <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>&gt;     --exclude-groups<span style=color:#f92672>=</span>system:unauthenticated <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>&gt;     --exclude-users<span style=color:#f92672>=</span>system:anonymous <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>&gt;     --additive-only<span style=color:#f92672>=</span>true <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>&gt;     --confirm
clusterrolebinding/self-provisioners
clusterrolebinding/system:build-strategy-docker-binding
clusterrolebinding/system:build-strategy-custom-binding
clusterrolebinding/system:build-strategy-source-binding
</code></pre></div><ul><li>Compare the difference</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=color:#f92672>--- describe-clusterPolicyBindings-default-before.txt        2016-06-01 09:24:28.030082834 -0700
</span><span style=color:#f92672></span><span style=color:#a6e22e>+++ describe-clusterPolicyBindings-default-after.txt 2016-06-01 09:26:18.664093120 -0700
</span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -2,7 +2,7 @@
</span><span style=color:#75715e></span> Created:                                               12 weeks ago
 Labels:                                                        &lt;none&gt;
 Annotations:                                           &lt;none&gt;
<span style=color:#f92672>-Last Modified:                                         2016-05-21 11:32:48 -0700 PDT
</span><span style=color:#f92672></span><span style=color:#a6e22e>+Last Modified:                                         2016-06-01 09:25:53 -0700 PDT
</span><span style=color:#a6e22e></span> Policy:                                                        &lt;none&gt;
 RoleBinding[basic-users]:
                                                        Role:                   basic-user
<span style=color:#75715e>@@ -31,7 +31,7 @@
</span><span style=color:#75715e></span> RoleBinding[self-provisioners]:
                                                        Role:                   self-provisioner
                                                        Users:                  &lt;none&gt;
<span style=color:#f92672>-                                                       Groups:                 system:authenticated
</span><span style=color:#f92672></span><span style=color:#a6e22e>+                                                       Groups:                 system:authenticated:oauth, system:authenticated
</span><span style=color:#a6e22e></span>                                                        ServiceAccounts:        &lt;none&gt;
                                                        Subjects:               &lt;none&gt;
 RoleBinding[system:build-controller]:
<span style=color:#75715e>@@ -43,19 +43,19 @@
</span><span style=color:#75715e></span> RoleBinding[system:build-strategy-custom-binding]:
                                                        Role:                   system:build-strategy-custom
                                                        Users:                  &lt;none&gt;
<span style=color:#f92672>-                                                       Groups:                 &lt;none&gt;
</span><span style=color:#f92672></span><span style=color:#a6e22e>+                                                       Groups:                 system:authenticated
</span><span style=color:#a6e22e></span>                                                        ServiceAccounts:        &lt;none&gt;
                                                        Subjects:               &lt;none&gt;
 RoleBinding[system:build-strategy-docker-binding]:
                                                        Role:                   system:build-strategy-docker
                                                        Users:                  &lt;none&gt;
<span style=color:#f92672>-                                                       Groups:                 &lt;none&gt;
</span><span style=color:#f92672></span><span style=color:#a6e22e>+                                                       Groups:                 system:authenticated
</span><span style=color:#a6e22e></span>                                                        ServiceAccounts:        &lt;none&gt;
                                                        Subjects:               &lt;none&gt;
 RoleBinding[system:build-strategy-source-binding]:
                                                        Role:                   system:build-strategy-source
                                                        Users:                  &lt;none&gt;
<span style=color:#f92672>-                                                       Groups:                 &lt;none&gt;
</span><span style=color:#f92672></span><span style=color:#a6e22e>+                                                       Groups:                 system:authenticated
</span><span style=color:#a6e22e></span>                                                        ServiceAccounts:        &lt;none&gt;
                                                        Subjects:               &lt;none&gt;
 RoleBinding[system:daemonset-controller]:
</code></pre></div><p>Now the source build strategy works again and the diagnostics output looks mostly reasonable. Not sure about the <code>self-provisioners</code> yet.</p><pre><code>[Note] Running diagnostic: ClusterRoleBindings
       Description: Check that the default ClusterRoleBindings are present and contain the expected subjects

Info:  clusterrolebinding/cluster-admins has more subjects than expected.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to remove extra subjects.

Info:  clusterrolebinding/cluster-admins has extra subject {User  dlbewley    }.

Info:  clusterrolebinding/cluster-readers has more subjects than expected.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to remove extra subjects.

Info:  clusterrolebinding/cluster-readers has extra subject {ServiceAccount management-infra management-admin    }.
Info:  clusterrolebinding/cluster-readers has extra subject {ServiceAccount openshift-infra heapster    }.
Info:  clusterrolebinding/cluster-readers has extra subject {User  sysdig    }.
Info:  clusterrolebinding/cluster-readers has extra subject {ServiceAccount openshift-infra sysdig    }.

Info:  clusterrolebinding/self-provisioners has more subjects than expected.

       Use the `oadm policy reconcile-cluster-role-bindings` command to update the role binding to remove extra subjects.

Info:  clusterrolebinding/self-provisioners has extra subject {SystemGroup  system:authenticated    }.
</code></pre><h1 id=hawkular-metrics>Hawkular Metrics</h1><p>It used to be that you had to know the metrics URL and visit <a href=https://metrics.os.example.com>https://metrics.os.example.com</a> and accept the cert so you could view the resource usage of your pods. There is now a nice link to this URL from the pod metrics page. However, even though I can vist the URL sucessfully, the metrics tab lists a <em>Forbidden</em> error at the bottom, and no graphs. I suspect this may be related to the metrics running <code>openshift3/metrics-hawkular-metrics:3.1.1</code> still.</p><p>I could just dump the stats and <a href=https://docs.openshift.com/enterprise/3.2/install_config/cluster_metrics.html>start over</a>, but I&rsquo;ll try updating the replication controllers first.</p><p>Get the list, and then use <code>oc edit</code> to set the version to 3.2.0.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc get rc -n openshift-infra -o wide
NAME                   DESIRED   CURRENT   AGE       CONTAINER<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>           IMAGE<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>                                                               SELECTOR
hawkular-cassandra-1   <span style=color:#ae81ff>1</span>         <span style=color:#ae81ff>1</span>         73d       hawkular-cassandra-1   registry.access.redhat.com/openshift3/metrics-cassandra:3.1.1          name<span style=color:#f92672>=</span>hawkular-cassandra-1
hawkular-metrics       <span style=color:#ae81ff>1</span>         <span style=color:#ae81ff>1</span>         73d       hawkular-metrics       registry.access.redhat.com/openshift3/metrics-hawkular-metrics:3.1.1   name<span style=color:#f92672>=</span>hawkular-metrics
heapster               <span style=color:#ae81ff>1</span>         <span style=color:#ae81ff>1</span>         73d       heapster               registry.access.redhat.com/openshift3/metrics-heapster:3.1.1           name<span style=color:#f92672>=</span>heapster
</code></pre></div><p>Edit the replication controller and change the image tag from <code>3.1.1</code> to <code>3.2.0</code></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc edit rc hawkular-cassandra-1
</code></pre></div><p>The pod needs to be removed so the replication controller can recreate it. I think you could pre-emptively pull the new image if you are worried about the downtime.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc get pods
NAME                         READY     STATUS    RESTARTS   AGE
hawkular-cassandra-1-t7mp5   1/1       Running   <span style=color:#ae81ff>0</span>          4d
hawkular-metrics-2ccne       1/1       Running   <span style=color:#ae81ff>0</span>          4d
heapster-6usys               1/1       Running   <span style=color:#ae81ff>4</span>          4d

$ oc delete pod hawkular-cassandra-1-t7mp5
pod <span style=color:#e6db74>&#34;hawkular-cassandra-1-t7mp5&#34;</span> deleted

$ oc get events --watch
</code></pre></div><p>Unfortunately I wound up with a <code>CrashLoopBackOff</code> for the cassandra pod. Watching the logs it seemed to be replaying transactions, so I&rsquo;m not sure if it was a timeout or what exactly.</p><pre><code>2016-05-20 21:03:15 -0700 PDT   2016-05-20 21:18:03 -0700 PDT   61        hawkular-cassandra-1-iwl9z   Pod       spec.containers{hawkular-cassandra-1}   Warning   BackOff   {kubelet ose-prod-node-06.example.com}   Back-off restarting failed docker container
2016-05-20 21:11:42 -0700 PDT   2016-05-20 21:18:03 -0700 PDT   30        hawkular-cassandra-1-iwl9z   Pod                 Warning   FailedSync   {kubelet ose-prod-node-06.example.com}   Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;hawkular-cassandra-1&quot; with CrashLoopBackOff: &quot;Back-off 5m0s restarting failed container=hawkular-cassandra-1 pod=hawkular-cassandra-1-iwl9z_openshift-infra(ac1669d8-1f08-11e6-8f0c-001a4a48be57)&quot;
</code></pre><pre><code>$ oc logs hawkular-cassandra-1-iwl9z -f
About to generate seeds
Trying to access the Seed list [try #1]
Trying to access the Seed list [try #2]
Trying to access the Seed list [try #3]
Setting seeds to be hawkular-cassandra-1-iwl9z
cat: /etc/ld.so.conf.d/*.conf: No such file or directory
CompilerOracle: inline org/apache/cassandra/db/AbstractNativeCell.compareTo (Lorg/apache/cassandra/db/composites/Composite;)I
CompilerOracle: inline org/apache/cassandra/db/composites/AbstractSimpleCellNameType.compareUnsigned (Lorg/apache/cassandra/db/composites/Composite;Lorg/apache/cassandra/db/composites/Composite;)I
CompilerOracle: inline org/apache/cassandra/io/util/Memory.checkBounds (JJ)V
CompilerOracle: inline org/apache/cassandra/io/util/SafeMemory.checkBounds (JJ)V
CompilerOracle: inline org/apache/cassandra/utils/AsymmetricOrdering.selectBoundary (Lorg/apache/cassandra/utils/AsymmetricOrdering/Op;II)I
CompilerOracle: inline org/apache/cassandra/utils/AsymmetricOrdering.strictnessOfLessThan (Lorg/apache/cassandra/utils/AsymmetricOrdering/Op;)I
CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare (Ljava/nio/ByteBuffer;[B)I
CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare ([BLjava/nio/ByteBuffer;)I
CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compareUnsigned (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I
CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/lang/Object;JI)I
CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/nio/ByteBuffer;)I
CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I
INFO  04:07:55 Loading settings from file:/opt/apache-cassandra-2.2.1.redhat-2/conf/cassandra.yaml
INFO  04:07:55 Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=true; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; cas_conte
ntion_timeout_in_ms=1000; client_encryption_options=&lt;REDACTED&gt;; cluster_name=hawkular-metrics; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_directory=/cassandra_data/commitlog; commit
log_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_counter_writes=32; concurrent_reads=32; concurrent_writes=32; counter
_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; cross_node_timeout=false; data_file_directories=[/cassandra_data/data]; disk_failure_policy=stop; dynamic_
snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb
=1024; incremental_backups=false; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; inter_dc_tcp_nodelay=false; internode_compression=all; key_cache_save_period=14400; key_ca
che_size_in_mb=null; listen_address=hawkular-cassandra-1-iwl9z; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; memtable_allocation_type=heap_buffers; native_transport_port=9042; num_tokens=
256; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.sc
heduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=hawkular-cassandra-1-iwl9z; rpc_keepalive=true; rpc_port=9160; rpc_server_type=sync; seed_pro
vider=[{class_name=org.hawkular.openshift.cassandra.OpenshiftSeedProvider, parameters=[{seeds=hawkular-cassandra-1-iwl9z}]}]; server_encryption_options=&lt;REDACTED&gt;; snapshot_before_compaction=false; ssl_st
orage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=true; storage_port=7000; thrift_framed_transport_size_in_mb=15; tombstone_failure_threshold=100000; tombs
tone_warn_threshold=1000; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
INFO  04:07:55 DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
INFO  04:07:56 Global memtable on-heap threshold is enabled at 125MB
INFO  04:07:56 Global memtable off-heap threshold is enabled at 125MB
WARN  04:07:56 UnknownHostException for service 'hawkular-cassandra-nodes'. It may not be up yet. Trying again
WARN  04:07:58 UnknownHostException for service 'hawkular-cassandra-nodes'. It may not be up yet. Trying again
WARN  04:08:00 UnknownHostException for service 'hawkular-cassandra-nodes'. It may not be up yet. Trying again
WARN  04:08:02 UnknownHostException for service 'hawkular-cassandra-nodes'. It may not be up yet. Trying again
...
</code></pre><p>Not only that, but it looks like there are some compatibility issues.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc logs heapster-jdpgi
exec: <span style=color:#e6db74>&#34;./heapster-wrapper.sh&#34;</span>: stat ./heapster-wrapper.sh: no such file or directory
</code></pre></div><p>There is a new debug command in 3.2, but I wasn&rsquo;t able to learn much from it other than the startup command for the pod.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc debug pod heapster-jdpgi
Debugging with pod/heapster-jdpgi-debug, original command: ./heapster-wrapper.sh --wrapper.username_file<span style=color:#f92672>=</span>/hawkular-account/hawkular-metrics.username --wrapper.password_file<span style=color:#f92672>=</span>/hawkular-account/hawkular-metrics.password --wrapper.allowed_users_file<span style=color:#f92672>=</span>/secrets/heapster.allowed-users --source<span style=color:#f92672>=</span>kubernetes:https://kubernetes.default.svc:443?useServiceAccount<span style=color:#f92672>=</span>true&amp;kubeletHttps<span style=color:#f92672>=</span>true&amp;kubeletPort<span style=color:#f92672>=</span><span style=color:#ae81ff>10250</span> --sink<span style=color:#f92672>=</span>hawkular:https://hawkular-metrics:443?tenant<span style=color:#f92672>=</span>_system&amp;labelToTenant<span style=color:#f92672>=</span>pod_namespace&amp;caCert<span style=color:#f92672>=</span>/hawkular-cert/hawkular-metrics-ca.certificate&amp;user<span style=color:#f92672>=</span>%username%&amp;pass<span style=color:#f92672>=</span>%password%&amp;filter<span style=color:#f92672>=</span>label<span style=color:#f92672>(</span>container_name:^/system.slice.*|^/user.slice<span style=color:#f92672>)</span> --logtostderr<span style=color:#f92672>=</span>true --tls_cert<span style=color:#f92672>=</span>/secrets/heapster.cert --tls_key<span style=color:#f92672>=</span>/secrets/heapster.key --tls_client_ca<span style=color:#f92672>=</span>/secrets/heapster.client-ca --allowed_users<span style=color:#f92672>=</span>%allowed_users%
</code></pre></div><h2 id=redeploy-cluster-metrics>Redeploy Cluster Metrics</h2><p>So, it seems there is some missing documentation here. I&rsquo;m going to go ahead and <a href=https://docs.openshift.com/enterprise/3.2/install_config/cluster_metrics.html>redeploy cluster metrics</a> instead of trying to fix it.</p><ul><li>Clear the decks and remove the old deployment</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc delete all --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;metrics-infra&#34;</span>
replicationcontroller <span style=color:#e6db74>&#34;hawkular-cassandra-1&#34;</span> deleted
replicationcontroller <span style=color:#e6db74>&#34;hawkular-metrics&#34;</span> deleted
replicationcontroller <span style=color:#e6db74>&#34;heapster&#34;</span> deleted
route <span style=color:#e6db74>&#34;hawkular-metrics&#34;</span> deleted
service <span style=color:#e6db74>&#34;hawkular-cassandra&#34;</span> deleted
service <span style=color:#e6db74>&#34;hawkular-cassandra-nodes&#34;</span> deleted
service <span style=color:#e6db74>&#34;hawkular-metrics&#34;</span> deleted
service <span style=color:#e6db74>&#34;heapster&#34;</span> deleted
pod <span style=color:#e6db74>&#34;hawkular-cassandra-1-iwl9z&#34;</span> deleted

$ oc delete templates --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;metrics-infra&#34;</span>
template <span style=color:#e6db74>&#34;hawkular-cassandra-node-emptydir&#34;</span> deleted
template <span style=color:#e6db74>&#34;hawkular-cassandra-node-pv&#34;</span> deleted
template <span style=color:#e6db74>&#34;hawkular-cassandra-services&#34;</span> deleted
template <span style=color:#e6db74>&#34;hawkular-heapster&#34;</span> deleted
template <span style=color:#e6db74>&#34;hawkular-metrics&#34;</span> deleted
template <span style=color:#e6db74>&#34;hawkular-support&#34;</span> deleted

$ oc delete secrets --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;metrics-infra&#34;</span>
secret <span style=color:#e6db74>&#34;hawkular-cassandra-certificate&#34;</span> deleted
secret <span style=color:#e6db74>&#34;hawkular-cassandra-secrets&#34;</span> deleted
secret <span style=color:#e6db74>&#34;hawkular-metrics-account&#34;</span> deleted
secret <span style=color:#e6db74>&#34;hawkular-metrics-certificate&#34;</span> deleted
secret <span style=color:#e6db74>&#34;hawkular-metrics-secrets&#34;</span> deleted
secret <span style=color:#e6db74>&#34;heapster-secrets&#34;</span> deleted

$ oc delete pvc --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;metrics-infra&#34;</span>
persistentvolumeclaim <span style=color:#e6db74>&#34;metrics-cassandra-1&#34;</span> deleted

$ oc delete sa --selector<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;metrics-infra&#34;</span>
serviceaccount <span style=color:#e6db74>&#34;cassandra&#34;</span> deleted
serviceaccount <span style=color:#e6db74>&#34;hawkular&#34;</span> deleted
serviceaccount <span style=color:#e6db74>&#34;heapster&#34;</span> deleted
</code></pre></div><p>The <em>Reclaim Policy</em> on the PV used by metrics is <em>retain</em>, so go empty out that volume before continuing.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc describe pv metrics
Name:           metrics
Labels:         &lt;none&gt;
Status:         Released
Claim:          openshift-infra/metrics-cassandra-1
Reclaim Policy: Retain
Access Modes:   RWO,RWX
Capacity:       50Gi
Message:
Source:
    Type:       NFS <span style=color:#f92672>(</span>an NFS mount that lasts the lifetime of a pod<span style=color:#f92672>)</span>
    Server:     openshift-data.example.com
    Path:       /openshift/prod/metrics
    ReadOnly:   false
</code></pre></div><ul><li>Deploy the metrics again and wait for it to complete.</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc process -f /usr/share/ansible/openshift-ansible/roles/openshift_examples/files/examples/v1.2/infrastructure-templates/enterprise/metrics-deployer.yaml <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>  -v HAWKULAR_METRICS_HOSTNAME<span style=color:#f92672>=</span>metrics.os.example.com <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>  | oc create -f -
</code></pre></div><ul><li>Now replace the hawkular route with a <a href=https://docs.openshift.com/enterprise/latest/install_config/cluster_metrics.html#metrics-reencrypting-route>reencrypting router</a></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc describe route hawkular-metrics
Name:                   hawkular-metrics
Created:                <span style=color:#ae81ff>2</span> hours ago
Labels:                 metrics-infra<span style=color:#f92672>=</span>support
Annotations:            &lt;none&gt;
Requested Host:         metrics.os.example.com
                          exposed on router ha-router-primary <span style=color:#ae81ff>2</span> hours ago
Path:                   &lt;none&gt;
TLS Termination:        passthrough
Insecure Policy:        &lt;none&gt;
Service:                hawkular-metrics
Endpoint Port:          &lt;all endpoint ports&gt;
Endpoints:              10.1.7.5:8444

$ oc describe service hawkular-metrics
Name:                   hawkular-metrics
Namespace:              openshift-infra
Labels:                 metrics-infra<span style=color:#f92672>=</span>hawkular-metrics,name<span style=color:#f92672>=</span>hawkular-metrics
Selector:               name<span style=color:#f92672>=</span>hawkular-metrics
Type:                   ClusterIP
IP:                     172.30.113.214
Port:                   https-endpoint  443/TCP
Endpoints:              10.1.7.5:8444
Session Affinity:       None
No events.
</code></pre></div><ul><li>Create <code>route-metrics-reencrypt.yaml</code> with the <em>wildcard.os.example.com</em> cert.</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ oc get routes
NAME               HOST/PORT              PATH      SERVICE            TERMINATION   LABELS
hawkular-metrics   metrics.os.example.com             hawkular-metrics   passthrough   metrics-infra<span style=color:#f92672>=</span>support

$ vim route-metrics-reencrypt.yaml

$ oc delete route hawkular-metrics
route <span style=color:#e6db74>&#34;hawkular-metrics&#34;</span> deleted

$ oc create -f route-metrics-reencrypt.yaml
route <span style=color:#e6db74>&#34;hawkular-metrics&#34;</span> created

$ oc get routes
NAME               HOST/PORT              PATH      SERVICE                 TERMINATION   LABELS
hawkular-metrics   metrics.os.example.com             hawkular-metrics:8444   reencrypt     metrics-infra<span style=color:#f92672>=</span>support
</code></pre></div><p>After this, metrics work again, even better! FWIW there is some mixed content on the page.</p><blockquote><p>Mixed Content: The page at &lsquo;<a href="https://metrics.os.example.com/hawkular/metrics'">https://metrics.os.example.com/hawkular/metrics'</a> was loaded over HTTPS, but requested an insecure stylesheet &lsquo;<a href="http://fonts.googleapis.com/css?family=Exo+2'">http://fonts.googleapis.com/css?family=Exo+2'</a>. This request has been blocked; the content must be served over HTTPS.</p></blockquote></div><div id=comments><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//dlbewleygithubio.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class=col-md-3><div class="panel panel-default sidebar-menu"><div class=panel-heading><h3 class=panel-title>Search</h3></div><div class=panel-body><form action=//google.com/search method=get accept-charset=utf-8 role=search><div class=input-group><input type=search name=q class=form-control placeholder=Search>
<input type=hidden name=sitesearch value=https://dwnwrd.github.io/>
<span class=input-group-btn><button type=submit class="btn btn-template-main"><i class="fas fa-search"></i></button></span></div></form></div></div><div class="panel sidebar-menu"><div class=panel-heading><h3 class=panel-title>Tagged</h3></div><div class=panel-body><ul class=tag-cloud><li class=active><a href=/tags/kubernetes><i class="fas fa-tags"></i>kubernetes</a></li><li class=active><a href=/tags/openshift><i class="fas fa-tags"></i>openshift</a></li><li class=active><a href=/tags/OSE3><i class="fas fa-tags"></i>OSE3</a></li><li class=active><a href=/tags/upgrade><i class="fas fa-tags"></i>upgrade</a></li></ul></div></div><div class="panel sidebar-menu"><div class=panel-heading><h3 class=panel-title>Tags</h3></div><div class=panel-body><ul class=tag-cloud><li><a href=/tags/CDK><i class="fas fa-tags"></i>CDK</a></li><li><a href=/tags/OCP3><i class="fas fa-tags"></i>OCP3</a></li><li><a href=/tags/OCP4><i class="fas fa-tags"></i>OCP4</a></li><li><a href=/tags/OSE3><i class="fas fa-tags"></i>OSE3</a></li><li><a href=/tags/RHEL><i class="fas fa-tags"></i>RHEL</a></li><li><a href=/tags/ansible><i class="fas fa-tags"></i>ansible</a></li><li><a href=/tags/automation><i class="fas fa-tags"></i>automation</a></li><li><a href=/tags/docker><i class="fas fa-tags"></i>docker</a></li><li><a href=/tags/draft><i class="fas fa-tags"></i>draft</a></li><li><a href=/tags/etcd><i class="fas fa-tags"></i>etcd</a></li><li><a href=/tags/git><i class="fas fa-tags"></i>git</a></li><li><a href=/tags/haproxy><i class="fas fa-tags"></i>haproxy</a></li><li><a href=/tags/heat><i class="fas fa-tags"></i>heat</a></li><li><a href=/tags/install><i class="fas fa-tags"></i>install</a></li><li><a href=/tags/kubernetes><i class="fas fa-tags"></i>kubernetes</a></li><li><a href=/tags/mac><i class="fas fa-tags"></i>mac</a></li><li><a href=/tags/metrics><i class="fas fa-tags"></i>metrics</a></li><li><a href=/tags/migration><i class="fas fa-tags"></i>migration</a></li><li><a href=/tags/monitoring><i class="fas fa-tags"></i>monitoring</a></li><li><a href=/tags/networking><i class="fas fa-tags"></i>networking</a></li><li><a href=/tags/openshift><i class="fas fa-tags"></i>openshift</a></li><li><a href=/tags/openstack><i class="fas fa-tags"></i>openstack</a></li><li><a href=/tags/operators><i class="fas fa-tags"></i>operators</a></li><li><a href=/tags/python><i class="fas fa-tags"></i>python</a></li><li><a href=/tags/router><i class="fas fa-tags"></i>router</a></li><li><a href=/tags/ssl><i class="fas fa-tags"></i>ssl</a></li><li><a href=/tags/troubleshooting><i class="fas fa-tags"></i>troubleshooting</a></li><li><a href=/tags/upgrade><i class="fas fa-tags"></i>upgrade</a></li><li><a href=/tags/vagrant><i class="fas fa-tags"></i>vagrant</a></li><li><a href=/tags/zabbix><i class="fas fa-tags"></i>zabbix</a></li><li><a href=/tags/zimbra><i class="fas fa-tags"></i>zimbra</a></li></ul></div></div></div></div></div></div><footer id=footer><div class=container><div class="col-md-4 col-sm-6"><h4>About us</h4><p>GUI Free Life is the personal, technical blog of Dale Bewley. Comments and opinions are my own and not that of my employers.</p><hr class="hidden-md hidden-lg hidden-sm"></div><div class="col-md-4 col-sm-6"><h4>Recent posts</h4><div class=blog-entries><div class="item same-height-row clearfix"><div class="image same-height-always"><a href=https://dwnwrd.github.io/blog/2021/03/09/Understanding-OpenShift-Over-The-Air-Updates/><img src=/images/the-face-of-a-computer-operator-from-the-2134th-communications-squadron-is-2ca9c9.jpg class=img-responsive alt="How do OpenShift Over The Air Updates Work?"></a></div><div class="name same-height-always"><h5><a href=https://dwnwrd.github.io/blog/2021/03/09/Understanding-OpenShift-Over-The-Air-Updates/>How do OpenShift Over The Air Updates Work?</a></h5></div></div><div class="item same-height-row clearfix"><div class="image same-height-always"><a href=https://dwnwrd.github.io/blog/2020/02/15/OpenShift-4-on-OpenStack-Networking-and-Installation/><img src=/images/openshift-openstack-install-network-00.png class=img-responsive alt="OpenShift 4 on OpenStack Networking and Installation"></a></div><div class="name same-height-always"><h5><a href=https://dwnwrd.github.io/blog/2020/02/15/OpenShift-4-on-OpenStack-Networking-and-Installation/>OpenShift 4 on OpenStack Networking and Installation</a></h5></div></div><div class="item same-height-row clearfix"><div class="image same-height-always"><a href=https://dwnwrd.github.io/blog/2019/05/09/Replace-Bootstrap-Kubeconfig/><img src=/img/banners/banner-5.jpg class=img-responsive alt="Playbook to replace bootstrap.kubeconfig and node certificates on OpenShift 3.10 3.11"></a></div><div class="name same-height-always"><h5><a href=https://dwnwrd.github.io/blog/2019/05/09/Replace-Bootstrap-Kubeconfig/>Playbook to replace bootstrap.kubeconfig and node certificates on OpenShift 3.10 3.11</a></h5></div></div></div><hr class="hidden-md hidden-lg"></div><div class="col-md-4 col-sm-6"><h4>Contact</h4><p class=text-uppercase><strong>Dale Bewley</strong><br>Oakland<br>California<br><strong>USA</strong></p><a href=/contact class="btn btn-small btn-template-main">Go to contact page</a><hr class="hidden-md hidden-lg hidden-sm"></div></div></footer><div id=copyright><div class=container><div class=col-md-12><p class=pull-left>Copyright (c) 2021, Dale Bewley; all rights reserved.</p><p class=pull-right>Template by <a href=https://bootstrapious.com/p/universal-business-e-commerce-template>Bootstrapious</a>.
Ported to Hugo by <a href=https://github.com/devcows/hugo-universal-theme>DevCows</a>.</p></div></div></div></div><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-78084690-1','auto'),ga('send','pageview'))</script><script src=//code.jquery.com/jquery-3.1.1.min.js integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin=anonymous></script><script src=//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js></script><script src="//maps.googleapis.com/maps/api/js?key=AIzaSyDacpwSIXi6lk2fS2wzZOSoh7iHm_ZP3UE&v=3.exp"></script><script src=/js/hpneo.gmaps.js></script><script src=/js/gmaps.init.js></script><script src=/js/front.js></script><script src=/js/owl.carousel.min.js></script></body></html>